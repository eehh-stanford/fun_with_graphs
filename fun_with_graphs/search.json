[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fun with Graphs",
    "section": "",
    "text": "Fun with Graphs\nIn the Fall of 1992, I was a first-year Ph.D. student in biological anthropology at Harvard. Mark Leighton was looking for someone to serve as a TF for his class, Primate Evolutionary Ecology. This was an amazing class that brought the theoretical evolutionary ecology of MacArthur and Levins and the behavioral ecology of Krebs, Davies, and Charnov to bear on problems of primate ecology. I didn’t need to teach, but I signed up anyway, hoping to really learn the material to which I had only a superficial introduction during undergraduate tutorials. This turned out to be a pretty fateful decision.\nOn every exam that Mark administered, there was a section cheekily titled Fun with Graphs, where students had to display their graphical reasoning chops. In general, I don’t think the students had all that much fun with this section. When Bill Durham and I first taught our class, Environmental Change and Emerging Infectious Disease, I brought back this tradition and it has been a staple of all my in-person exams for classes I’ve taught at Stanford ever since.\nI worry that the sort of intuitive graphical reasoning that motivated so much of this incredible theory is not developed in students who must expend all their effort studying for tests which will allow them admission to increasingly competitive universities. I also worry that theoretical ecologists (along with formal demographers and mathematical epidemiologists) have not reproduced themselves culturally and this important material is increasingly not taught.\nYou could think of this book as essentially Nonstandard Uses of R. R graphics are clearly designed for plotting data. However, R is a highly versatile and powerful tool for making theoretical and expository figures in science. That’s the vibe. Maybe there will be more…"
  },
  {
    "objectID": "graphs.html#some-definitions",
    "href": "graphs.html#some-definitions",
    "title": "3  Actual Graphs",
    "section": "3.1 Some Definitions",
    "text": "3.1 Some Definitions\nA graph is simply a collection of vertices (or nodes) and edges (or ties). We can denote this \\(\\mathcal{G}(V,E)\\), where \\(V\\) is a the vertex set and \\(E\\) is the edge set. The vertices of the graph represent the actors in the social system. These are usually individual people, but they could be households, geographical localities, institutions, or other social entities. The edges of the graph represent the relations between these entities (e.g., “is friends with” or “has sexual intercourse with” or “sends money to”). These edges can be directed (e.g., “sends money to”) or undirected (e.g., “within 2 meters of”).\nWhen the relations that define the graph are directional, we have a directed graph or digraph.\nGraphs (and digraphs) can be binary (i.e., presence/absence of a relationship) or valued (e.g., “groomed five times in the observation period”, “sent $100”).\nA graph (with no self-loops) with \\(n\\) vertices has \\({n \\choose 2} = n(n-1)/2\\) possible unordered pairs. This number (which can get very big!) is important for defining the density of a graph, i.e., the fraction of all possible relations that actually exist in a network.\nA bipartite graph is a graph where all the nodes of a graph can be partitioned into two sets \\(\\mathcal{V}_1\\) and \\(\\mathcal{V}_2\\) such that for all edges in the graph connects and unordered pair where one vertex comes from \\(\\mathcal{V}_1\\) and the other from \\(\\mathcal{V}_2\\). Often called an “affiliation graph” as bipartite graphs are used to represent people’s affiliations to organizations or events."
  },
  {
    "objectID": "graphs.html#various-ways-to-specify-graphs-in-igraph",
    "href": "graphs.html#various-ways-to-specify-graphs-in-igraph",
    "title": "3  Actual Graphs",
    "section": "3.2 Various Ways to Specify Graphs in igraph",
    "text": "3.2 Various Ways to Specify Graphs in igraph\nThe R package igraph provides tools for the analysis and visualization of networks. The package is actually just a set of R bindings for functions written in C++ that can be used in a variety of environments (e.g., native, R, Python).\n\n3.2.1 Specifying Small Graphs\nWe can create a small, undirected graph of five vertices from a vector of vertex pairs using the function make_graph():\n\nrequire(igraph)\ng <- make_graph( c(1,2, 1,3, 2,3, 2,4, 3,5, 4,5), n=5, dir=FALSE )\nplot(g, vertex.color=\"skyblue2\")\n\n\n\n\nThe call to the function make_graph() (which can be shortened to graph()) takes three arguments in this case. First, we enumerate the edges by listing the pairs of vertices which are connected. In this graph, there are six edges. Second, we define the size of our graph. This simple graph has five vertices, so n=5. Third, the default graph type is directed, so to create an undirected graph, we need to specify dir=FALSE. The function graph() creates a graph object which, like any R object, is associated with a number of methods. When we plot a graph object, the plotting method used is plot.igraph(). There are a number of features (or perhaps peculiarities) of the defaults of plot.igraph(). First, is the vertex color. It’s not hideous but it’s not an obvious choice for a default color either. Second, the default font label style is Roman, which can make the labels look cluttered. I typically change to a sens-serif font using the argument vertex.label.family=\"Helvetica\". Third, the layout will not necessarily make sense to you as a human viewer of the graph and will typically change each time you call plot.igraph(). Fortunately, igraph has a number of excellent tools for assisting with graph layout.\nFor small graphs representing the relationships between a few named individuals, we can create a graph using graph_from_literal(). Undirected edges are indicated with one or more dashes -, --, etc. It doesn’t matter how many dashes you use – you can use as many as you want to make your code more readable. The colon operator : links “vertex sets” – i.e., creates ties between all members of two groups of vertices. So, for the Scooby Gang, we could specify the following graph\n\ng <- graph_from_literal(Fred-Daphne:Velma-Shaggy, Fred-Shaggy-Scooby)\nplot(g, vertex.shape=\"none\", vertex.label.color=\"black\")\n\n\n\n\nFor directed edges, use -+ where the plus indicates the direction of the arrow, i.e., A --+ B creates a directed edge from A to B. A mutual edge can be created using +-+."
  },
  {
    "objectID": "graphs.html#a-note-on-visualizing-graphs",
    "href": "graphs.html#a-note-on-visualizing-graphs",
    "title": "3  Actual Graphs",
    "section": "3.3 A Note On Visualizing Graphs",
    "text": "3.3 A Note On Visualizing Graphs\nYou will notice that many of the graphs in these notes are a bit cramped. This happens because when I render the Quartz document, R generates fairly small .png files. If you have, for example, vertex labels that really need to be read, it is a good idea to send your plot to a file that uses a vector-based format and potentially make it big. My preference is .pdf, but an argument can be made that .svg is even better. To do this, you just need to wrap your plotting commands in call to .pdf: pdf(file=\"filename.pdf\", height14, width=14) and then don’t forget to close this off (i.e., after all your plotting commands) with dev.off() or you’ll keep sending graphics to your pdf file! The default size for pdf is \\(7 \\times 7\\) (in inches). By specifying the optional arguments height and width, we’ve doubled the size of the plot. This will spread things out quite a bit and you may actually have to increase the size of your vertices, labels, etc."
  },
  {
    "objectID": "graphs.html#special-graphs",
    "href": "graphs.html#special-graphs",
    "title": "3  Actual Graphs",
    "section": "3.4 Special Graphs",
    "text": "3.4 Special Graphs\nA wide variety of special graphs are built into igraph. Note: I really don’t like the current default color in igraph (a kind of sickly orange), so I set the vertex color for every plot – you don’t have to do that\n\n3.4.1 Empty, Full, Ring\n\n# empty graph\ng0 <- make_empty_graph(20)\nplot(g0, vertex.color=\"skyblue2\", vertex.size=10, vertex.label=NA)\n\n\n\n# full graph\ng1 <- make_full_graph(20)\nplot(g1, vertex.color=\"skyblue2\", vertex.size=10, vertex.label=NA)\n\n\n\n# ring\ng2 <- make_ring(20)\nplot(g2, vertex.color=\"skyblue2\", vertex.size=10, vertex.label=NA)\n\n\n\n\n\n\n3.4.2 Lattice, Tree, Star\n\n# lattice\ng3 <- make_lattice(dimvector=c(10,10))\nplot(g3, vertex.color=\"skyblue2\", vertex.size=10, vertex.label=NA)\n\n\n\n# tree\ng4 <- make_tree(20, children = 3, mode = \"undirected\")\nplot(g4, vertex.color=\"skyblue2\", vertex.size=10, vertex.label=NA)\n\n\n\n# star\ng5 <- make_star(20, mode=\"undirected\")\nplot(g5, vertex.color=\"skyblue2\", vertex.size=10, vertex.label=NA)\n\n\n\n\n\n\n3.4.3 Erdos-Renyi & Power-Law\n\n# Erdos-Renyi Random Graph\ng6 <- sample_gnm(n=100,m=50)\nplot(g6, vertex.color=\"skyblue2\", vertex.size=5, vertex.label=NA)\n\n\n\n# Power Law\ng7 <- sample_pa(n=100, power=1.5, m=1,  directed=FALSE)\nplot(g7, vertex.color=\"skyblue2\", vertex.size=5, vertex.label=NA)"
  },
  {
    "objectID": "graphs.html#working-with-graphs",
    "href": "graphs.html#working-with-graphs",
    "title": "3  Actual Graphs",
    "section": "3.5 Working with Graphs",
    "text": "3.5 Working with Graphs\n\n3.5.1 Putting Graphs Together\nSometimes you want to plot two (or more) graphs together. The disjoint union operator allows you to merge two graphs with different vertex sets:\n\nplot(g4 %du% g7, vertex.color=\"skyblue2\", vertex.size=5, vertex.label=NA)\n\n\n\n\n\n\n3.5.2 Rewiring and Connected Components\nWe often want to shuffle the edges of our graph around. A common application of this functionality is when we want to randomize the edges of a graph while maintaining the same vertex set and overall number of edges.\nWhen you rewire a graph, there is a chance you will create isolates (i.e., vertices with no incident edges). For visualization purposes, you often want to remove these. You frequently will want to extract the largest connected subcomponent of your graph.\nA subgraph is a graph \\(\\mathcal{G}^{\\prime}\\) where all the vertices and edges are also in graph \\(\\mathcal{G}\\). Subgraphs can be generated by selecting either vertices or the edges from \\(\\mathcal{G}\\). A component is a maximally connected subgraph of a graph (i.e., a path exists between all vertices in the subgraph). The igraph function subcomponent() will find all the subcomponents of your graph and order them in terms of their size. The largest subcomponent will be first, so you will often want to subset your graph (g) using the criterion subcomponent(g,1).\n\ngg <- g4 %du% g7\ngg <- rewire(gg, each_edge(prob = 0.3))\nplot(gg, vertex.color=\"skyblue2\", vertex.size=5, vertex.label=NA)\n\n\n\n## retain only the connected component\ngg <- induced_subgraph(gg, subcomponent(gg,1))\nplot(gg, vertex.color=\"skyblue2\", vertex.size=5, vertex.label=NA)\n\n\n\n\n\n\n3.5.3 Vertex and Edge Attributes\nYou can add arbitrary attributes to both vertices and edges. Generally, you do this to store information for plotting: colors, edge weights, names, etc. Some attributes are automatically created when you construct an graph object (e.g., “name” or “weight” if you load a weighted adjacency matrix)\n\nV(g) accesses vertex attributes\nE(g) accesses edge attributes\n\n\n## look at the structure\ng4\n\nIGRAPH 12addec U--- 20 19 -- Tree\n+ attr: name (g/c), children (g/n), mode (g/c)\n+ edges from 12addec:\n [1] 1-- 2 1-- 3 1-- 4 2-- 5 2-- 6 2-- 7 3-- 8 3-- 9 3--10 4--11 4--12 4--13\n[13] 5--14 5--15 5--16 6--17 6--18 6--19 7--20\n\nV(g4)$name <- LETTERS[1:20]\n## see how it's changed\ng4\n\nIGRAPH 12addec UN-- 20 19 -- Tree\n+ attr: name (g/c), children (g/n), mode (g/c), name (v/c)\n+ edges from 12addec (vertex names):\n [1] A--B A--C A--D B--E B--F B--G C--H C--I C--J D--K D--L D--M E--N E--O E--P\n[16] F--Q F--R F--S G--T\n\n## see what I did there?\n## hexadecimal color codes\nV(g4)$vertex.color <- \"#4503fc\"\nE(g4)$edge.color <- \"#abed8e\"\ng4\n\nIGRAPH 12addec UN-- 20 19 -- Tree\n+ attr: name (g/c), children (g/n), mode (g/c), name (v/c),\n| vertex.color (v/c), edge.color (e/c)\n+ edges from 12addec (vertex names):\n [1] A--B A--C A--D B--E B--F B--G C--H C--I C--J D--K D--L D--M E--N E--O E--P\n[16] F--Q F--R F--S G--T\n\nplot(g4, vertex.size=15, vertex.label=NA, vertex.color=V(g4)$vertex.color, \n     vertex.frame.color=V(g4)$vertex.color,\n     edge.color=E(g4)$edge.color, edge.width=3)"
  },
  {
    "objectID": "graphs.html#data-formats",
    "href": "graphs.html#data-formats",
    "title": "3  Actual Graphs",
    "section": "3.6 Data Formats",
    "text": "3.6 Data Formats\n\n3.6.1 Adjacency Matrices\nWe can represent the relationships of a social network using a matrix. A matrix is simply a rectangular array of numbers with (n) rows and \\(k\\) columns. It is conventional to denote matrices mathematically using capital letters and boldface, such as \\(\\mathbf{A}\\). We indicate the \\(ij\\)th element (i.e., the element corresponding to row \\(i\\) and column \\(j\\)) of \\(\\mathbf{A}\\) as \\(a_{ij}\\). A sociomatrix or adjacency matrix is a square matrix (i.e., \\(n \\times n\\), where \\(n\\) is the number of vertices in the network). It is typically binary, with \\(a_{ij}=1\\) if individuals \\(i\\) and \\(j\\) share an edge and \\(a_{ij}=0\\) otherwise. Consider a triangle:\n\n# generate a triangle\ng <- graph( c(1,2, 2,3, 1,3), n=3, dir=FALSE)\n### coordinatess to make the triangle look nice\ntri.coords <- matrix( c(228,416, 436,0, 20,0), nr=3, nc=2, byrow=TRUE)\npar(mfrow=c(1,2))\nplot(g, vertex.color=\"skyblue2\",vertex.label.family=\"Helvetica\")\nplot(g, layout=tri.coords, vertex.color=\"skyblue2\",vertex.label.family=\"Helvetica\")\n\n\n\n\nThe sociomatrix corresponding to our triangle is\n\\[\\begin{equation}\n\\mathbf{A} = \\left[ \\begin{array}{cccc}\n0   &  1   & 1 \\\\\n1   &  0   & 1 \\\\\n1   &  1   & 0  \\end{array} \\right].\n\\end{equation}\\]\nBy convention, the diagonal elements of a sociomatrix are all zero (i.e., self-loops are not allowed). Sociomatrix \\(\\mathbf{A}\\) in the equation above is symmetric (\\(a_{ij} = a_{ji}\\)) because the graph is undirected. For a digraph, the upper triangle (i.e., matrix elements above the diagonal) of the sociomatrix will generally be different than the lower triangle.\nMost primatologists/behavioral ecologists probably have experience thinking in terms of adjacency matrices. An example of an adjacency matrix is the pairwise interaction matrices (e.g., agonistic or affiliative interactions) that we construct from behavioral observations.\nA very important potential gotcha: when you read data into R, it will be in the form of a data frame. Converting an adjacency matrix to an igraph graph object requires the data to be in the matrix class. Therefore, you need to coerce the data you read in by wrapping your read.table() in an as.matrix() command.\n\nkids <- as.matrix(\n  read.table(\"data/strayer_strayer1976-fig2.txt\",\n                             header=FALSE)\n  )\nkid.names <- c(\"Ro\",\"Ss\",\"Br\",\"If\",\"Td\",\"Sd\",\"Pe\",\"Ir\",\"Cs\",\"Ka\",\n                \"Ch\",\"Ty\",\"Gl\",\"Sa\", \"Me\",\"Ju\",\"Sh\")\ncolnames(kids) <- kid.names\nrownames(kids) <- kid.names\ng <- graph_from_adjacency_matrix(kids, mode=\"directed\", weighted=TRUE)\nlay <- layout_with_fr(g)\nplot(g, layout=lay, edge.arrow.size=0.5,\n     vertex.color=\"skyblue2\", vertex.label.family=\"Helvetica\", \n     vertex.frame.color=\"skyblue2\")\n\n\n\n\nNote that you might want to change some of the graphics parameters depending on the type of display you use. For this document, the figures are constrained to be small, so you don’t want edges – and particularly arrows – to be too thick.\n\n\n3.6.2 Edge Lists\nAdjacency matrices are actually very inefficient. The cost of an adjacency matrix increases as \\(k^2\\). However, most sociomatrices are quite sparse, meaning that most entries in a sociomatrix are zero. We can capitalize on this by using a sparse-matrix representation. In social network analysis, this representation is called an edge list and it is much more efficient than storing relational data in matrix format.\nAn edgelist is simply a two-column matrix in which each row represents a (possibly directed) edge between the vertex listed in first column and the second column."
  },
  {
    "objectID": "graphs.html#community-structure",
    "href": "graphs.html#community-structure",
    "title": "3  Actual Graphs",
    "section": "3.7 Community Structure",
    "text": "3.7 Community Structure\nVarious algorithms for detecting clusters of similar vertices – i.e., “communities.” Use fastgreedy.community() to identify clusters in Kapferer’s tailor shop and color the vertices based on their membership.\n\nA <- as.matrix(\n  read.table(file=\"data/kapferer-tailorshop1.txt\", \n             header=TRUE, row.names=1)\n  )\nG <- graph.adjacency(A, mode=\"undirected\", diag=FALSE)\nfg <- fastgreedy.community(G)\ncols <- c(\"blue\",\"red\",\"black\",\"magenta\")\nplot(G, vertex.shape=\"none\",\n     vertex.label.cex=0.75, edge.color=grey(0.85), \n     edge.width=1, vertex.label.color=cols[fg$membership],\n     vertex.label.family=\"Helvetica\")\n\n\n\n# another approach to visualizing\nplot(fg,G,vertex.label=NA)\n\n\n\n\nfastgreedy.community() identified four clusters. These clusters are listed as numbers in fg$membership. We can then use this vector to index vertex colors."
  },
  {
    "objectID": "graphs.html#graph-layouts",
    "href": "graphs.html#graph-layouts",
    "title": "3  Actual Graphs",
    "section": "3.8 Graph Layouts",
    "text": "3.8 Graph Layouts\n\n3.8.1 Force-Based Layouts\nThe two most common layouts are Fruchterman-Reingold and Kawai-Kamada.\nSometimes you don’t want a force-based layout. You may have noticed that the lattice we plotted when we introduced make_lattice() was a bit funky. This is because for a force-based layout, vertices on the periphery will have very different forces working on them than those in the center.\n\nTo get a proper lattice layout, specify that you want it on a grid\n\n\nplot(g3, vertex.color=\"skyblue2\", \n     layout=layout_on_grid(g3,10,10), vertex.size=10, vertex.label=NA)\n\n\n\n\n\n\n3.8.2 Making Graph Layouts “By Hand”\nThe layout is of any given plot is random (e.g., plot the same graph repeatedly and you’ll see that the layout changes with each plot). igraph provides a tool for tinkering with the layout called tkplot(). Call tkplot() and it will open an X11 window (on Macs at least). Select and drag the vertices into the layout you want, then use tkplot.getcoords(gid) to get the coordinates (where gid is the graph id returned when calling tkplot() on your graph).\n\n\n\n\ntkplot() window of triangle graph\n\n\n\n\ng <- graph( c(1,2, 2,3, 1,3), n=3, dir=FALSE)\nplot(g, \n     vertex.color=\"skyblue2\", \n     vertex.frame.color=\"skyblue2\", vertex.label.family=\"Helvetica\")\n\n\n\n#tkplot(g)\n#tkplot.getcoords(1)\n### do some stuff with tkplot() and get coords which we call tri.coords\n## tkplot(g)\n## tkplot.getcoords(1) ## the plot id may be different depending on how many times you've called tkplot()\n##     [,1] [,2]\n##[1,]  228  416\n##[2,]  436    0\n##[3,]   20    0\ntri.coords <- matrix( c(228,416, 436,0, 20,0), nr=3, nc=2, byrow=TRUE)\npar(mfrow=c(1,2))\nplot(g, vertex.color=\"skyblue2\",\n     vertex.frame.color=\"skyblue2\", \n     vertex.label.family=\"Helvetica\")\nplot(g, layout=tri.coords, \n     vertex.color=\"skyblue2\", \n     vertex.frame.color=\"skyblue2\", vertex.label.family=\"Helvetica\")"
  },
  {
    "objectID": "graphs.html#plotting-affiliation-graphs",
    "href": "graphs.html#plotting-affiliation-graphs",
    "title": "3  Actual Graphs",
    "section": "3.9 Plotting Affiliation Graphs",
    "text": "3.9 Plotting Affiliation Graphs\n\ndavismat <- as.matrix(\n  read.table(file=\"data/davismat.txt\", \n            row.names=1, header=TRUE)\n  )\nsouthern <- graph_from_incidence_matrix(davismat) \nV(southern)$shape <- c(rep(\"circle\",18), rep(\"square\",14))\nV(southern)$color <- c(rep(\"blue\",18), rep(\"red\", 14))\nplot(southern, layout=layout.bipartite)\n\n\n\n## not so beautiful\n## did some tinkering using tkplot()...\nx <- c(rep(23,18), rep(433,14))\ny <- c(44.32432,   0.00000, 132.97297,  77.56757,  22.16216, 110.81081, 155.13514,\n       199.45946, 177.29730, 243.78378, 332.43243, 410.00000, 387.83784, 354.59459,\n       310.27027, 221.62162, 265.94595, 288.10811,   0.00000,  22.16216,  44.32432,\n       66.48649,  88.64865, 132.97297, 166.21622, 199.45946, 277.02703, 365.67568,\n       310.27027, 343.51351, 387.83784, 410.00000)\nsouthern.layout <- cbind(x,y)\nplot(southern, layout=southern.layout, vertex.label.family=\"Helvetica\")\n\n\n\n\n\nThe incidence matrix is \\(n \\times k\\), where \\(n\\) is the number of actors and \\(k\\) is the number of events\nProject the incidence matrix \\(X\\) into social space, creating a sociomatrix \\(A\\), \\(\\mathbf{A} = \\mathbf{X}\\, \\mathbf{X}^T\\)\nThis transforms the \\(n \\times k\\) into an \\(n \\times n\\) sociomatrix\n\n\n#Sociomatrix\n(f2f <- davismat %*% t(davismat))\n\n          EVELYN LAURA THERESA BRENDA CHARLOTTE FRANCES ELEANOR PEARL RUTH\nEVELYN         8     6       7      6         3       4       3     3    3\nLAURA          6     7       6      6         3       4       4     2    3\nTHERESA        7     6       8      6         4       4       4     3    4\nBRENDA         6     6       6      7         4       4       4     2    3\nCHARLOTTE      3     3       4      4         4       2       2     0    2\nFRANCES        4     4       4      4         2       4       3     2    2\nELEANOR        3     4       4      4         2       3       4     2    3\nPEARL          3     2       3      2         0       2       2     3    2\nRUTH           3     3       4      3         2       2       3     2    4\nVERNE          2     2       3      2         1       1       2     2    3\nMYRNA          2     1       2      1         0       1       1     2    2\nKATHERINE      2     1       2      1         0       1       1     2    2\nSYLVIA         2     2       3      2         1       1       2     2    3\nNORA           2     2       3      2         1       1       2     2    2\nHELEN          1     2       2      2         1       1       2     1    2\nDOROTHY        2     1       2      1         0       1       1     2    2\nOLIVIA         1     0       1      0         0       0       0     1    1\nFLORA          1     0       1      0         0       0       0     1    1\n          VERNE MYRNA KATHERINE SYLVIA NORA HELEN DOROTHY OLIVIA FLORA\nEVELYN        2     2         2      2    2     1       2      1     1\nLAURA         2     1         1      2    2     2       1      0     0\nTHERESA       3     2         2      3    3     2       2      1     1\nBRENDA        2     1         1      2    2     2       1      0     0\nCHARLOTTE     1     0         0      1    1     1       0      0     0\nFRANCES       1     1         1      1    1     1       1      0     0\nELEANOR       2     1         1      2    2     2       1      0     0\nPEARL         2     2         2      2    2     1       2      1     1\nRUTH          3     2         2      3    2     2       2      1     1\nVERNE         4     3         3      4    3     3       2      1     1\nMYRNA         3     4         4      4    3     3       2      1     1\nKATHERINE     3     4         6      6    5     3       2      1     1\nSYLVIA        4     4         6      7    6     4       2      1     1\nNORA          3     3         5      6    8     4       1      2     2\nHELEN         3     3         3      4    4     5       1      1     1\nDOROTHY       2     2         2      2    1     1       2      1     1\nOLIVIA        1     1         1      1    2     1       1      2     2\nFLORA         1     1         1      1    2     1       1      2     2\n\ngf2f <- graph_from_adjacency_matrix(f2f, mode=\"undirected\", diag=FALSE, add.rownames=TRUE)\ngf2f <- simplify(gf2f)\nplot(gf2f, vertex.color=\"skyblue2\",vertex.label.family=\"Helvetica\")\n\n\n\n## who is the most central?\ncb <- betweenness(gf2f)\n#plot(gf2f,vertex.size=cb*10, vertex.color=\"skyblue2\")\nplot(gf2f,vertex.label.cex=1+cb/2, vertex.shape=\"none\",vertex.label.family=\"Helvetica\")\n\n\n\n\n\nProject the matrix into event space\n\n\n### this gives you the number of women at each event (diagonal) or mutually at 2 events\n(e2e <- t(davismat) %*% davismat)\n\n    E1 E2 E3 E4 E5 E6 E7 E8 E9 E10 E11 E12 E13 E14\nE1   3  2  3  2  3  3  2  3  1   0   0   0   0   0\nE2   2  3  3  2  3  3  2  3  2   0   0   0   0   0\nE3   3  3  6  4  6  5  4  5  2   0   0   0   0   0\nE4   2  2  4  4  4  3  3  3  2   0   0   0   0   0\nE5   3  3  6  4  8  6  6  7  3   0   0   0   0   0\nE6   3  3  5  3  6  8  5  7  4   1   1   1   1   1\nE7   2  2  4  3  6  5 10  8  5   3   2   4   2   2\nE8   3  3  5  3  7  7  8 14  9   4   1   5   2   2\nE9   1  2  2  2  3  4  5  9 12   4   3   5   3   3\nE10  0  0  0  0  0  1  3  4  4   5   2   5   3   3\nE11  0  0  0  0  0  1  2  1  3   2   4   2   1   1\nE12  0  0  0  0  0  1  4  5  5   5   2   6   3   3\nE13  0  0  0  0  0  1  2  2  3   3   1   3   3   3\nE14  0  0  0  0  0  1  2  2  3   3   1   3   3   3\n\nge2e <- graph_from_adjacency_matrix(e2e, mode=\"undirected\", diag=FALSE, add.rownames=TRUE)\nge2e <- simplify(ge2e)\nplot(ge2e, vertex.size=20, vertex.color=\"skyblue2\",vertex.label.family=\"Helvetica\")"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Baalen, M. van, and M. W. Sabelis. 1995. “The Dynamics of Multiple\nInfection and the Evolution of Virulence.” American\nNaturalist 146 (6): 881–910. http://www.jstor.org/stable/2463102.\n\n\nBelovsky, G. E. 1987. “Hunter-Gatherer Foraging: A Linear\nProgramming Approach.” Journal of Anthropological\nArchaeology 6 (1): 29–76. https://doi.org/10.1016/0278-4165(87)90016-X.\n\n\nCharnov, Eric L. 1976. “Optimal Foraging, the Marginal Value\nTheorem.” Theoretical Population Biology 9 (2): 129–36.\nhttps://doi.org/10.1016/0040-5809(76)90040-X.\n\n\n———. 1997. “Trade-Off-Invariant Rules for Evolutionary Stable Life\nHistories.” Nature 387 (6631): 393–94. https://doi.org/10.1038/387393a0.\n\n\nEfferson, Charles, Sonja Vogt, and Ernst Fehr. 2020. “The Promise\nand the Peril of Using Social Influence to Reverse Harmful\nTraditions.” Nature Human Behaviour 4 (1): 55–68. https://doi.org/10.1038/s41562-019-0768-2.\n\n\nGadgil, Madhav, and William H. Bossert. 1970. “Life Historical\nConsequences of Natural Selection.” The American\nNaturalist 104 (935): 1–24. http://www.jstor.org/stable/2459070.\n\n\nHenrich, Joseph. 2004. “Demography and Cultural Evolution: How\nAdaptive Cultural Processes Can Produce Maladaptive Losses: The\nTasmanian Case.” American Antiquity 69 (2):\n197–214. https://doi.org/10.2307/4128416.\n\n\nLeslie, P., and B. Winterhalder. 2002. “Demographic Consequences\nof Unpredictability in Fertility Outcomes.” American Journal\nof Human Biology 14 (2): 168–83. https://doi.org/10.1002/ajhb.10044.\n\n\nLevins, R. 1968. Evolution in Changing Environments. Princeton:\nPrinceton University Press.\n\n\nLevins, Richard. 1962. “Theory of Fitness in a Heterogeneous\nEnvironment. I. The Fitness Set and Adaptive\nFunction.” The American Naturalist 96 (891): 361–73. http://www.jstor.org/stable/2458725.\n\n\nMay, R. M. 1976. “Simple Mathematical-Models with Very Complicated\nDynamics.” Nature 261 (5560): 459–67. https://doi.org/10.1038/261459a0.\n\n\nOrians, Gordon H. 1969. “On the Evolution of Mating Systems in\nBirds and Mammals.” The American Naturalist 103 (934):\n589–603. https://doi.org/10.1086/282628.\n\n\nParker, G. A., and R. A. Stuart. 1976. “Animal Behavior as a\nStrategy Optimizer: Evolution of Resource Assessment Strategies and\nOptimal Emigration Thresholds.” American Naturalist 110\n(976): 1055–76. https://doi.org/10.1086/283126.\n\n\nRogers, A. R. 1988. “Does Biology Constrain Culture?”\nAmerican Anthropologist 90 (4): 819–31. https://doi.org/10.1525/aa.1988.90.4.02a00030.\n\n\nRogers, E. M. 2003. Diffusion of Innovations. 5th ed. New York:\nFree Press.\n\n\nRosenzweig, M. L., and R. H. MacArthur. 1963. “Graphical\nRepresentation and Stability Conditions of Predator-Prey\nInteractions.” The American Naturalist 97 (895): 209–23.\nhttps://doi.org/10.1086/282272.\n\n\nScheffer, M. 2009. Critical Transitions in Nature and Society.\nPrinceton: Princeton University Press.\n\n\nSmith, C. C., and S. D. Fretwell. 1974. “The Optimal Balance\nBetween Size and Number of Offspring.” American\nNaturalist 108: 499–506. https://www.jstor.org/stable/2459681.\n\n\nStevens, M. Henry. 2009. A Primer of Ecology with r. Edited by\nM. HenryH Stevens. New York: Springer. https://doi.org/10.1007/978-0-387-89882-7.\n\n\nZeeman, E. C. 1976. “Catastrophe Theory.” Scientific\nAmerican 234 (4): 65–65 &. https://doi.org/10.1038/scientificamerican0476-65."
  },
  {
    "objectID": "drawing.html#introduction",
    "href": "drawing.html#introduction",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\nR has powerful graphics capabilities. While we typically use these for plotting data, we can also make publication-quality plots for elucidating theoretical topics as well.\nThese notes are a very tentative start to a much larger body of work. I hope they are nonetheless helpful in their rather incomplete form."
  },
  {
    "objectID": "drawing.html#the-taylor-series-approximation-is-your-friend",
    "href": "drawing.html#the-taylor-series-approximation-is-your-friend",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.2 The Taylor-Series Approximation is Your Friend",
    "text": "2.2 The Taylor-Series Approximation is Your Friend\nYou may be familiar with Taylor polynomials (or series) and how useful they are for applied mathematics and science. A Taylor series allows you to approximate a function \\(f(x)\\) in terms of an infinite sum of its derivatives taken at a single point \\(a\\):\n\\[ f(x) = f(a) + f'(a)(x-a) + \\frac{f''(a)(x-a)^2}{2!} + \\frac{f'''(a)(x-a)^3}{3!} + \\cdots\n\\]\nWhen we truncate the Taylor series at the first term, we produce a linear approximation of our function. In other words, it’s a tangent line. It turns out that we often want to draw tangents in theoretical figures and just as the Taylor series can help us derive theory, so too can it help us generate plots!\n\n2.2.1 Cobb-Douglas Production Function\nThe Cobb-Douglas production function is a model for production that is the product of two power functions. The classic model combines capital (\\(K\\)) and labor \\(L\\). The inputs are raised to powers \\(\\alpha\\) and \\(\\beta\\).\n\\[ W = K^{\\alpha} L^{\\beta}\n\\]\nIn the Cobb-Douglas form, the exponents also turn out to be the elasticities of production with respect to the inputs. So, suppose that \\(\\alpha=0.25\\), this means that a 1% increase in the capital will increase overall wealth by 0.25%.\nIf \\(\\alpha + \\beta =1\\), then there are constant returns to scale: doubling inputs will double the output. If, on the other hand, \\(\\alpha + \\beta > 1\\), there are increasing returns to scale so that doubling inputs will more than double the output.\nThe optimal balance between capital and labor occurs when a budget line is tangent to this curve.\n\nx <- seq(0,0.8,length=100)\nL <- seq(0,1,length=100)\nK <- (1/L^0.7)^(1/0.3)\n#derivative\nfprime <- -5.6/(0.3^2.4)\n# make a function to calculate K from L\nkf <- function(L) (2/L^0.7)^(1/0.5)\n# pick an arbitrary point for tangency\na <- 0.3\n\n\nplot(L,kf(L), type=\"l\", lwd=2, axes=FALSE, frame=TRUE, \n     yaxs=\"i\", xaxs=\"i\", \n     xlim=c(0,1), ylim=c(0,50), \n     col=grey(0.65), \n     xlab=\"Labor\", ylab=\"Capital\")\n# tangent\nlines(x, kf(a)+fprime*(x-a), lwd=1, col=\"black\")\n# values on the axes\nsegments(0.3,0,0.3,kf(0.3), col=grey(0.65), lty=3)\nsegments(-0.1,kf(0.3),0.3,kf(0.3), col=grey(0.65), lty=3)\nmtext(expression(hat(L)),1,at=0.3, padj=0.5)\nmtext(expression(hat(K)),2, at=kf(0.3), adj=2, padj=0.5, las=2)\n\n\n\n\nGraphics Tip: Note that in labeling the optimum value of capital, we used the argument las=2. This says to print text always perpendicular to the axis and is useful for labeling interesting points on particularly the vertical axis.\nYou will notice that in most of these plots, we suppress the axis labeling. For a theoretical plot, we want to see the shape of the relationships between variables and care less about the specific \\((x,y)\\) values. This means that we typically include in the plot() command the argument axes=FALSE. When we turn off the axes, this also, by default, removes the frame around the axes. We usually want that, so we have to also include the argument frame=TRUE.\nWe can add mathematical, typset material to any text (e.g., axis labels, labels for equilibria and other interesting points, titles, etc.) using expression(). There is a stripped-down markup language for this in R. To learn more, do a help search for plotmath.\n\n\n2.2.2 Marginal Value Theorem\nSomething like the Marginal Value Theorem (MVT), a phrase coined by Charnov (1976), appears in many applications: foraging theory (Charnov 1976), sexual selection (Parker and Stuart 1976), the evolution of virulence (Baalen and Sabelis 1995), and of course, life history theory (Smith and Fretwell 1974). If you pay careful attention, you will notice that it’s always the maximization of some sort of ratio, where the numerator and denominator trade-off. In this case, the MVT solution arises naturally from the quotient rule for differtiation. The MVT states that the optimal value of the ratio fitness measure can be found when a straight line rooted at the origin is tangent to the fitness/constraint function. This the eponymous “marginal value.”\nIn previous examples, we specified the tangent point. Here we solve for the optimal value, which for the marginal value theorem, says that the rate is maximized where a line rooted at the origin is tangent to the utility function. We can mess around with different slopes and try to find something that’s approximately right or we can find the actual solution using the root-finding function in R. I need to acknowledge Mike Price here because he helped me get unstuck as I flailed to get uniroot() to work. I should also note that when I publish notes like this, even if I accompany them with caveats about incompleteness, you are seeing the product of lots of trial and error (lots of error, I assure you). Remember, the struggle is part of the scientific process.\nAnyway, code for the marginal value theorem (in its many guises).\n\nx <- seq(0,20,length=500)\n# utility function fp> 0 fpp < 0\n# turns out that RMarkdown does not handle comments with single quotes \n# fp == deriv of f; fpp == 2nd deriv of f\nf <- function(x) {\n  1 - exp(-0.2*(x-1))\n}\n# derivative of the utility function\nfprime <- function(x) {\n  0.2*exp(-0.2*x)*exp(0.2)\n}\n\n# f + fp*(z-x) = 0\n# z = x -(f/fp)\n# solve for tangency; find the root of this\nxinter <- function(x) {\n  return(x - f(x)/fprime(x))\n}\n\nsoln <- uniroot(xinter,c(0,10))\n\nplot(x,f(x), type=\"l\", lwd=2, xaxs=\"i\", yaxs=\"i\",\n     xlab=\"Time\",\n     ylab=\"Rate of Gain\",\n     ylim=c(0,1))\nlines(x,(f(soln$root)/soln$root)*x,col=\"red\")\nsegments(soln$root,0,soln$root,f(soln$root), lty=2, col=\"red\")\nsegments(0,f(soln$root),soln$root,f(soln$root), lty=2, col=\"red\")\nmtext(expression(hat(t)),1,at=soln$root, padj=1)\n## some non-optimal adaptive functions\nlines(x,(f(2)/2)*x,col=grey(0.85))\nlines(x,(f(1.5)/1.5)*x,col=grey(0.85))\nlines(x,(f(11)/11)*x,col=grey(0.85))\n\n\n\n\nMarginal value theorem plot. A line rooted at the origin that is tangent to the gain curve provides the optimal patch-residence time, \\(\\hat{t}\\).\nGraphics Tip: In this case, we had to find the point where a line rooted at the orgin is tangent to the gain curve. We found this using uniroot() which is a one-dimensional optimization routine that searches an interval for the zero of a function. The function returns an list with at least four elements. The one we want is called root, hence the use of soln$root in plotting arguments in the above code.\n\n\n2.2.3 Optimal Age at First Reproduction\nSimple Example of the optimal trade-off between adult reproductive value (\\(E\\)) and juvenile recruitment (\\(S\\)). Charnov (1997) has suggested that fitness is a product, broadly construed, of three things: juvenile recruitment, annual fertility of adults, and adult life expectancy. In turn, these elements can be combined. For example, the product of annual fertility and adult life expectancy can be thought of as adult reproductive value because it is the expected total reproduction over the an individual’s lifespan, conditional on them being recruited into the breeding population. As Charnov notes, these things are likely to trade-off. Moreover, the multiplicative form of fitness makes these trade-offs particularly straightforward to visualize and analyze.\nWhen we plot the allowable combinations of \\(\\log(S)\\) and \\(\\log(E)\\), we get a convex plot of the iso-fitness plot linking the logs of \\(E\\) and \\(S\\), which indicates diminishing marginal returns in both dimensions. The optimal life history is the one for which a line with a slope of -1 is tangent to this iso-fitness constraint curve. Why? The fitness measure (assuming population stationarity) is \\(R_0 = S\\, E\\). Take logs such that \\(\\log(R_0) = \\log E + \\log S\\) and differentiate with respect to age at first reproduction (\\(\\alpha\\); which, in Charnov’s formalism, is the control parameter for the life history):\n\\[ \\frac{d \\log R_0}{d\\alpha} = \\frac{d \\log E}{d\\alpha} + \\frac{d \\log S}{d\\alpha}.\n\\]\nSet this equal to zero and rearrange. Divide \\(d\\log E/d\\log \\alpha\\) by \\(d\\log S/d\\log \\alpha\\) and we find the optimality criterion:\n\\[ \\frac{d\\log E}{d \\log S} = -1.\n\\]\n\ng <- seq(0,sqrt(1/5),length=200)\nh <- sqrt(1-(5*g^2))\nhf <- function(g) sqrt(1-(5*g^2))\n## derivative\nfp <- function(g) -5*g/sqrt(1-5*g^2)\n\n# solve for tangency; find the root of this\n# note the sign change\nginter <- function(g) {\n  return(g + hf(g)/fp(g))\n}\n\n## do not search over whole interval \n## because g values > sqrt(5) will give NaNs!\na <- uniroot(ginter,c(0,0.4))$root\n## this simply extends the plotting range \n## so that the tangent line fills the plotting range\ngg <- seq(0,0.5+a,length=500)\n\nplot(g,hf(g), type=\"l\", lwd=2, axes=FALSE, frame=TRUE, \n     yaxs=\"i\", xaxs=\"i\", \n     ylim=c(0,1.1), xlim=c(0,0.5), \n     xlab=\"log(E)\", \n     ylab=\"log(S)\")\n## first-order Taylor Series approx\nlines(gg, hf(a)+fp(a)*(gg-a), col=\"red\")\nsegments(a,0,a,hf(a), col=grey(0.65), lty=3)\nsegments(-0.1,hf(a),a,hf(a), col=grey(0.65), lty=3)\nmtext(expression(hat(E)),1,at=a, padj=0.5)\nmtext(expression(hat(S)),2, at=hf(a), adj=2, padj=0.5, las=2)\n\n\n\n\n\n\n2.2.4 Fitness Sets\nRichard Levins (1962) introduced a the idea of fitness sets as a way to think about evolution in variable environments. This approach was more fully fleshed out in his subsequent monograph (R. Levins 1968). The fundamental idea is to represent the fitness of organisms in the different conditions that make up their variable environments and then find the strategy that maximizes fitness across these environments. The optimum can be a generalized compromise across the different environments or it can be the production of polymorphic specialized phenotypes that better match specific environmental conditions.\nConsider first a population with two phenotypes where the peak fitness in the two environments are quite separated from each other such that the fitness functions do not overlap tremendously. It’s conventional to assume Gaussian distributions of fitnesses with respect to the environment for simplicity, but to make things more interesting, we can use Gamma distributions, which will have more right-skew. The basic idea behind using these peaked functions is that there is an optimum for the environment and that fitness falls off as you move away from this optimum value of the phenotype. A Gaussian distribution just makes quite specific assumptions about how fitness falls off as the phenotype differs from the optimum: it does so symmetrically around the maximum and it declines exponentially in the squared difference from the optimum, while the Gamma distributions will be asymmetric in the way fitness falls off from the peak. The actual form of the fitness function will depend on the particulars of the environment and the phenotypes in question.\n\n## skewed gamma distributions\nx <- seq(0,25,,1000)\nk1 <- 9\ns1 <- 0.5\nk2 <- 7.5\ns2 <- 1\n\nplot(x,dgamma(x,shape=k1,scale=s1), type=\"l\", lwd=2,\n     axes = FALSE, frame=TRUE,\n     xlab=\"Phenotype\", ylab=\"Fitness\")\nlines(x,dgamma(x,shape=k2,scale=s2))\n\n\n\n\nIn this figure, we plotted the fitness functions against the environment. We can cut out the middleman, as it were, and simply plot the fitness functions against each other in a manner analogous to phase-plane analysis of, e.g., the Lotka-Volterra predator-prey model. Environment becomes implicit in the plots. What we have done is represent all possible phenotypes in our 2-dimensional fitness space.\nA quick note on convexity is probably warranted here. A space is said to be convex if, for any two points contained within the space, the entirety of the line segment that connects these points is also contained within the space. It’s easy to see that a line segment connecting points in horns of this fitness set would not be entirely contained within the set.\nOur two distributions overlap quite a bit and we will see that they form a convex fitness set. This suggests the geometrical interpretation of convexity, namely, that it implies the ability of a compromise phenotype. To find the optimal (compromise) phenotype, we add the adaptive function for a coarse-grained environment. For a coarse-grained environment, the adaptive function will have a hyperbolic form. Here again, the issue of convexity arises. An adaptive function that takes the hyperbolic form as in figure 3, is also said to be convex. Just as a convex fitness set implies an an optimum phenotype that is a compromise, convexity in the adaptive function suggests that average values have higher fitness than extremes. As the adaptive-function isoclines move from the center to the extremes, the increase in fitness in one dimension must be greater than the reduction of fitness in the other dimension. This is also related to diminishing marginal rate of substitution. Note, for example, as the isocline moves away from its convex center upward in the direction of \\(W_2\\), it takes increasing fitness in the \\(W_2\\) dimension to make up for lost fitness in the \\(W_1\\) direction.\n\n## for the isoclines\nG <- seq(0,0.5,length=100)\nalpha <- 0.5\nbeta <- 0.5\n# simple function to calculate hyperbolic isolclines following Cobb-Douglas form\nkf <- function(G,W,alpha,beta) (W/G^alpha)^(1/beta)\n\n## fitness set\nplot(dgamma(x,shape=k1,scale=s1),dgamma(x,shape=k2,scale=s2), lwd=3,\n     type=\"l\", axes = FALSE, las=1,\n     xlim=c(0,0.4), ylim=c(0,0.25),\n     xlab=expression(W[1]), ylab=expression(W[2]))\nbox()\n## convex adaptive functions\nlines(G,kf(G=G,W=0.05,alpha=0.75,beta=1), lty=2)\nlines(G,kf(G=G,W=0.05,alpha=0.85,beta=1), lty=2)\nlines(G,kf(G=G,W=0.05,alpha=0.63,beta=1), lty=2)\n\n\n\n\n\n\n2.2.5 Graphical Newton-Raphson Method\nAnother cool application of tangent lines in plots illustrates the popular and powerful family of optimization algorithms are broadly known as “Newton’s Method’ or the”Newton-Raphson Algorithm.” This algorithm finds roots of functions – that is, points where the function is zero. The basic idea is that we start from an initial guess point on our function. We then draw a line tangent to our function at this point. Finding the \\(x\\)-intercept for the tangent line, we repeat the process only this time drawing our tangent line from the point on the curve corresponding to the \\(x\\)-intercept of our last tangent line. It turns out that, for some initial guess, \\(x_0\\), the value \\(x_1 = x_0 - f(x_0)/f'(x_0)\\) is a better estimate of the root. We can then repeat this process until we are satisfactorily close to the root of the function. We can make a quick graphical demonstration Newton’s method for a very simple function \\(y=x^2-9\\). We start with a guess at \\(x=8\\). The plot shows three iterations (numbered sequentially). We can see that each iteration gets much closer to the root of this equation (at \\(x=3\\)). In fact, it gets so close after three steps that plotting another iteration is indistinguishable from the correct solution (though for a realistic tolerance, it would take a couple more steps to get right to \\(x=3\\)).\n\n## graphical newton-method\n\nx <- seq(0,10, length=100)\ny <- function(x) x^2 - 9\nx1 <- function(a) a-y(a)/(2*a)\n\n# first iteration\na <- 8\nplot(x,y(x),type=\"l\",lwd=3)\nabline(h=0)\npoints(8,55, pch=19, cex=1.5)\ntext(8,59,\"1\")\nlines(x, y(a) + (x-a)*2*a, col=\"red\")\n# second iteration\npoints(x1(a),y(x1(a)), pch=19, cex=1.5)\ntext(x1(a),y(x1(a))+4,\"2\")\na <- x1(a)\nlines(x, y(a) + (x-a)*2*a, col=\"red\")        \n# third iteration\npoints(x1(a),y(x1(a)), pch=19,cex=1.5)\ntext(x1(a),y(x1(a))+4,\"3\")\na <- x1(a)\nlines(x, y(a) + (x-a)*2*a, col=\"red\")  \n\n\n\n\nIf we were really feeling ambitious, we could animate this!"
  },
  {
    "objectID": "drawing.html#fold-catastrophe-model",
    "href": "drawing.html#fold-catastrophe-model",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.4 Fold-Catastrophe Model",
    "text": "2.4 Fold-Catastrophe Model\nA catastrophe is a sudden shift in system state (Zeeman 1976). An interesting form of catastrophe, which Scheffer (2009) discusses in detail, is the fold catastrophe.\nThis is a pretty complicated figure. The solid parts of the curve are stable – when the system state is perturbed when in the vicinity of this part of the attractor, it tends to return, as indicated by the grey arrows pointing back to the attractor. The dashed part of the attractor is unstable – perturbations in this neighborhood tend to move away from the attractor. This graphical representation of the system makes it pretty easy to see how a small perturbation could dramatically change the system if the current combination of conditions and system state place the system on the attractor near the neighborhood where the attractor changes from stable to unstable. The figure illustrates one such scenario. The conditions/system state start at point \\(F1\\). A small forcing perturbs the system off this point across the bifurcation. Further forcing now moves the system way off the current state to some new, far away, stable state. We go from a very high value of the system state to a very low value with only a very small change in conditions. Indeed, in this figure, the conditions remain constant from point \\(F1\\) to the new value indicated by the white point – just a brief perturbation was sufficient to cause the drastic change.\n\nx <- seq(-12,12,length=10000)\ny <- seq(12,10/sqrt(3), length=1000)\n## fold-catastrophe is a cubic\nplot(-x^3+100*x,x,type=\"l\", axes=FALSE, lwd=2, lty=2, \n     xlab=\"Conditions\", ylab=\"System State\")\nbox()\nlines(-y^3+100*y,y, lwd=2)\nlines(y^3-100*y,-y, lwd=2)\n\n# unstable\narrows(-200,-5,-200,-2.75, code=1, lwd=3, length=0.1, col=grey(0.75))\narrows(-200,-1.5,-200, 0.75, code=2, lwd=3, length=0.1, col=grey(0.75))\n#lower stable\narrows(-200,-6,-200, -8.25, code=2, lwd=3, length=0.1, col=grey(0.75))\narrows(-200,-11.5,-200, -9.25, code=2, lwd=3, length=0.1, col=grey(0.75))\n#upper stable\narrows(-200,13.5,-200, 11.25, code=2, lwd=3, length=0.1, col=grey(0.75))\narrows(-200,8.25,-200, 10.5, code=2, lwd=3, length=0.1, col=grey(0.75))\n# use locator() to find coordinates\npoints(357,7, pch=21, cex=2, lwd=3, bg=grey(0.75))\ntext(376.6749, 7.87279, \"F1\")\npoints(357,-11.452987, pch=21, cex=2, bg=\"white\")\narrows(357,6.5,357,4, lwd=3, length=0.1)\narrows(357,3.5,357,-10.8, code=2, lwd=3, length=0.1, col=grey(0.75))\n\n\n\n\nGraphics Tip: For the fold catastrophe, we want the upper and lower arms of the curve to be solid lines, indicating a that the attractor lies in a basin of attraction in these regions, and a dashed line in the middle, indicating that the attractor is unstable there. To do this we plot the whole curve as a dashed line lty=2 and then plot solid lines over this curve in the regions we want it to be solid. Lots of trial-and-error in making such a plot!\n\n2.4.1 Mechanistic Foundation of Fold-Catastrophe\nThe fold-castastrophe may seem like an incredibly specific model. It turns out there are various very natural ways of constructing such an attractor. Here, we discuss the approach of (noy-meier1975?) for a resource-exploitation case.\n\n# Logistic Recruitment\nlogistic.recruit <- expression(r*N*(1 - (N/K)^theta))\nno <- 1\nr <- 0.45\nK <- 100\ntheta <- 1\nN <- seq(0,K,length=500)\n\n# Holling Type II Functional Response\nh2 <- expression(a*N/(b + a*x))\nx <- N+1\na <- 0.7\nb <- 3\nplot(N,eval(logistic.recruit), type=\"l\", yaxs=\"i\", lwd=3, axes=FALSE, xlab=\"Relative Producer Density\", ylab=\"Relative Productivity\", ylim=c(0,15))\nbox()\nlines(x, 6*eval(h2), lwd=2)\nlines(x, 12*eval(h2), lwd=2)\n\npoints(c(8.702413, 36.521362, 57.497146, 85.464859), c(3.485678, 10.441517, 11.003335,  5.652690), col=c(\"red\",\"red\",\"green\",\"green\"), cex=2, pch=16)\narrows(36.521362-7.5, 10.441517+2, 36.521362-1, 10.441517+2, code=1, lwd=3, length=0.1, col=grey(0.75))\narrows(36.521362+1, 10.441517+2, 36.521362+7.5, 10.441517+2, code=2, lwd=3, length=0.1, col=grey(0.75))\n#\narrows(57.497146-7.5, 10.441517+2, 57.497146-1, 10.441517+2, code=2, lwd=3, length=0.1, col=grey(0.75))\narrows(57.497146+1, 10.441517+2, 57.497146+7.5, 10.441517+2, code=1, lwd=3, length=0.1, col=grey(0.75))\ntext(c(59.13355, 86.65497), c(11.458140,  6.107494), c(\"F2\", \"F1\"))\n\n\n\n\nThere are three fixed points where the recruitment curve and the extraction curve intersect. The green points are stable fixed points, whereas the red points are unstable. The third set of points is near zero and I’ve not drawn those just to keep the plot less cluttered. This fixed point is also stable.\nIf we imagine keeping the recruitment curve constant but sweeping extraction curves continuously up through the space (as we have for one big jump in the plot from \\(F1\\) to \\(F2\\)) and tracked the three fixed points along this sweeping, we would have a fold catastrophe."
  },
  {
    "objectID": "drawing.html#cobwebbing",
    "href": "drawing.html#cobwebbing",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.5 Cobwebbing",
    "text": "2.5 Cobwebbing\nWith a discrete-time model in one dimension (e.g., an unstructured population model), we can trace the dynamics as we iterate the model forward using a technique called cobwebbing. Here’s a quick example of a Ricker recruitment model, a density-dependent population model with the feature that it overcompensates when numbers exceed the carrying capacity. When the population of highly reactive (i.e., has strong growth potential), this tendency for overcompensation can lead to some pretty wild dynamics. This plot shows such a case.\n\n## Ricker recruitment function\nricker.recruit <- function(r0,K,N) N*exp(r0*(1-(N/K)))\n## fast growth!\nr0 <- 3\nK <- 50\nN <- 0:150\nn0 <- 25\n## iterate model for 10 time steps\nt <- 10\ny <- rep(0,t)\ny[1] <- ricker.recruit(r0=r0,K=K,N=n0)\nfor(i in 2:t)  y[i] <- ricker.recruit(r0=r0,K=K,N=y[i-1])\n\nplot(N,ricker.recruit(r0=r0,K=K,N=N), type=\"l\", col=\"black\", lwd=3, yaxs=\"i\",\n     ylim=c(0,150),\n     xlab=\"Current Number of Infections\", ylab=\"New Infections\")\nabline(a=0,b=1, lwd=2, col=grey(0.75))\nsegments(n0,0,n0,y[1], col=\"red\")\nsegments(n0,y[1],y[1],y[1], col=\"red\")\nfor(i in 2:(t-2)){\n    segments(y[i],y[i],y[i],y[i+1], col=\"red\") #vertical\n    segments(y[i],y[i+1],y[i+1],y[i+1], col=\"red\") #horiz\n    segments(y[i+1],y[i+1],y[i+1],y[i+2], col=\"red\") #vert\n    segments(y[i+1],y[i+2],y[i+2],y[i+2], col=\"red\") #horiz\n}\n\n\n\n## this could very easily be made into a function (and probably should be)\n\nThis population model with highly over-compensatory dynamics will never settle down. It always overshoots or undershoots and so fluctuates wildly. May (1976) notes that we can measure the strength of the response by the slope of the recruitment function at its equilibrium value (i.e., where the grey line of equality intersects with the recruitment function). Using the tools we’ve discussed in these note, we could calculate that slope and draw a tangent line at that point!"
  },
  {
    "objectID": "drawing.html#polygons",
    "href": "drawing.html#polygons",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.9 Polygons",
    "text": "2.9 Polygons\nTo create a polygon between two curves, \\(y_1\\) and \\(y_2\\), which are both functions of \\(x\\), you need to pass polygon() a concatenated vector of \\(x\\) and the reverse of \\(x\\) for the first vector, and then a concatenated vector of \\(y_2\\) and the reverse of \\(y_1\\) for the second vector.\nHere, fill in the polygon formed between the convex part of a logistic curve and a straight line that connects its endpoints.\n\nx <- seq(10,30,,500)\nux <- function(a,b,x) 1/(1+exp(-(x-a)/b))\na <- 20\nb <- 1.75\n\nx1 <- seq(10,20,,250)\n# straight line\ny1 <- (x1-10)/20\n# convex part of logistic\ny2 <- ux(a=a,b=b,x=x1)\n\n\nplot(x,ux(a=a,b=b,x=x), type=\"l\", lwd=3, axes=FALSE, frame=TRUE, \n     xaxs=\"i\",\n     xlab=\"Time\", ylab=\"Technological Development\")\nsegments(10,ux(a=a,b=b,x=10),30, ux(a=a,b=b,x=30), lwd=2, col=grey(0.85))\npolygon(c(x1, rev(x1)), c(y2, rev(y1)), col=\"plum\")\n\n\n\n\nProbably one of the most common uses for polygons is to fill in the tail (or some other part) of a probability density to show how much relative probability is contained in an interval or a tail. Here we compare the tail probability of a standard normal distribution with a low-df \\(t\\) distribution. We will color in the upper tail above the value of 1.96, the approximate 97.5th quantile of the standard normal distribution and the conventional definition of “statistical significance.”\n\n## normal\nz <- seq(-20, 20, length=2000)\np <- dnorm(z)\nplot(z,p, type=\"l\", lwd=2, xlim=c(-4,4), \n     xlab=\"Outcome\", ylab=\"Probability of Outcome\")\nz0 <- z[z >= 1.96]    # define region to fill\nz0 <- c(z0[1], z0)\np0 <- p[z >= 1.96]\np0 <- c(0, p0)\npolygon(z0, p0, col=\"grey\")\n\n\n\n# integrate to see how much probability mass is in the tail\nintegrate(dnorm, 1.96, Inf)\n\n0.0249979 with absolute error < 1.9e-05\n\n\nNow for the \\(t\\) distribution\n\n## t, df=1\nq <- dt(z,df=1)\nplot(z,q, type=\"l\", lwd=2, xlab=\"Outcome\", ylab=\"Probability of Outcome\")\nt0 <- z[z >= 1.96]    # define region to fill\nt0 <- c(t0[1], t0)\nq0 <- q[z >= 1.96]\nq0 <- c(dt(20,df=1), q0)\npolygon(t0, q0, col=\"grey\")\n\n\n\n## integrate to see how much probability mass is in the tail\nintegrate(dt, 1.96, Inf, df=1)\n\n0.1501714 with absolute error < 1.1e-10\n\n\nOoh, pointy. Note that the \\(t\\) distribution decays so slowly that you can see that the polygon has a slope to it even when you extend the range out to 20. This explains why we added dt(20,df=1) as the first element of the q variable for the polygon."
  },
  {
    "objectID": "interpreting.html#introduction",
    "href": "interpreting.html#introduction",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.1 Introduction",
    "text": "1.1 Introduction\nUnderstanding scientific figures is an important part of becoming a scientist or a critical consumer of scientific information. This is a skill that, alas, is generally not taught in most schools. Here, I will try to provide a gentle introduction to reading scientific figures, especially theoretical plots. I have companion notes that describe how to generate scientific plots in R.\nWe use theory in science to bring order to the complexity we observe in the world. Theory generates our hypotheses but it also guides us in what we observe, how we measure it, and what we should find surprising. Surprise is essential for the scientific enterprise because it is the surprise that comes when we observe something novel from a process we thought we understood that generates innovation and explanation.\nA couple starting points. We will use some very basic calculus here. Derivatives, second derivatives, and Taylor series."
  },
  {
    "objectID": "interpreting.html#lines",
    "href": "interpreting.html#lines",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.2 Lines",
    "text": "1.2 Lines\nPresumably, we all remember the formula for a straight line from high school algebra:\n\\[\ny = mx + b,\n\\]\nwhere \\(m\\) is the slope and \\(b\\) is the \\(y\\)-intercept.\n\nm <- 2\nb <- 1\ncurve(m*x+b, 0, 10, lwd=3, xlab=\"x\", ylab=\"y\")\n\n\n\n\nClearly, this is a straight line. What this means is that for whatever \\(x\\)-value you increment, you will increase by a factor of two.\n\n# define a linear function\nlin <- function(x,m=2,b=1) m*x + b\n# draw curve, add increments\ncurve(lin(x), 0, 10, lwd=3, xlab=\"x\", ylab=\"y\")\nsegments(1,lin(1),3,lin(1), col=\"red\", lty=3)\nsegments(3,lin(1),3,lin(3), col=\"red\", lty=3)\nsegments(4,lin(4),6,lin(4), col=\"red\", lty=3)\nsegments(6,lin(4),6,lin(6), col=\"red\", lty=3)\nsegments(7,lin(7),9,lin(7), col=\"red\", lty=3)\nsegments(9,lin(7),9,lin(9), col=\"red\", lty=3)\n\n\n\n\nOf course, we can show this analytically by calculating the derivative. Let \\(f(x) = mx + b\\), then \\(f'(x) = m\\). Not surprising since \\(m\\) is literally the slope that the rate of change in \\(f(x)\\) is always \\(m\\).\nLinear change is a touchstone. We are often interested if something is changing faster or more slowly than linear.\nWe often use linear functions to approximate more complex functions in some restricted range. For example, in the model of optimal virulence, discussed below, we need to draw a tangent line to the function relating transmissibility to disease-induced mortality. This tangent line is a linear approximation of that function in the vicinity of the optimal virulence.\nNote that this is what a derivative is. It’s linear representation of the slope of a function over an infinitesimal change of the input variable."
  },
  {
    "objectID": "interpreting.html#curves",
    "href": "interpreting.html#curves",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.3 Curves",
    "text": "1.3 Curves\n\n1.3.1 Polynomial Curves\nWhen something is nonlinear, it changes at different rates in different parts of the curve. The simplest extension from a straight line is a polynomial, e.g., a quadratic function.\n\n# quadratic function\nquad <- function(x,m=2,b=1) m*x^2+b\ncurve(quad(x), 0, 10, lwd=3, xlab=\"x\", ylab=\"y\")\nsegments(1,quad(1),3,quad(1), col=\"red\", lty=3)\nsegments(3,quad(1),3,quad(3), col=\"red\", lty=3)\nsegments(4,quad(4),6,quad(4), col=\"red\", lty=3)\nsegments(6,quad(4),6,quad(6), col=\"red\", lty=3)\nsegments(7,quad(7),9,quad(7), col=\"red\", lty=3)\nsegments(9,quad(7),9,quad(9), col=\"red\", lty=3)\n\n\n\n\nThe quadratic curve changes at an increasing rate. For \\(f(x) = mx^2 + b\\), \\(f'(x)=2x\\).\n\n\n1.3.2 Exponential and Logarithmic Curves\nWhen people say that something is growing “exponentially,” what they usually mean is that it’s growing fast. Exponential growth is much more specific than that (and there are, indeed, ways to grow much faster than exponentially!). In continuous time, something grows exponentially if it increases at a constant rate regardless of its size.\nExponential growth has the wild property that the derivative of an exponential is proportional to the exponential itself. For example, if \\(f(x)=e^r\\), then \\(f'(x) = e^r\\). If \\(f(x)=e^{2r}\\), then \\(f'(x) = 2e^{2r}\\), and so on.\n\ncurve(exp(x), 0, 10, lwd=3, xlab=\"x\", ylab=\"y\")\nsegments(1,exp(1),3,exp(1), col=\"red\", lty=3)\nsegments(3,exp(1),3,exp(3), col=\"red\", lty=3)\nsegments(4,exp(4),6,exp(4), col=\"red\", lty=3)\nsegments(6,exp(4),6,exp(6), col=\"red\", lty=3)\nsegments(7,exp(7),9,exp(7), col=\"red\", lty=3)\nsegments(9,exp(7),9,exp(9), col=\"red\", lty=3)\n\n\n\n\nLooking at the increments, we quickly discern another important feature of exponential growth: it sneaks up on you! In the early phase of an exponential-growth process, it can be quite difficult to tell it apart from linear growth or even no growth. The red dotted lines showing the growth between \\(x=1\\) and \\(x=3\\) are barely visible.\nBecause of the explosiveness of exponential growth, the initial conditions can matter a lot for outcomes. Compare the following two curves:\n\ncurve(5*exp(x), 0, 10, lwd=3, col=\"red\", xlab=\"x\", ylab=\"y\")\ncurve(1*exp(x), 0, 10, lwd=3, col=\"black\", add=TRUE)\n\n\n\n\nWe predict that virulence of a virus, for example, will increase with the size of the infectious innoculum. The intuition behind this prediction is that a larger innoculum provides a larger initial population size that can quickly increase to overwhelm a host’s immunological defenses. The smaller size of the viral population for any given time after infection arising from the smaller innoculum provides a greater likelihood that the host will control the infection quickly and with less tissue damage, etc.\nIt’s also super-important to note that things can also decrease exponentially! Exponential decay is a thing.\n\ncurve(50*exp(-x), 0, 10, lwd=3, xlab=\"x\", ylab=\"y\")\nsegments(1,50*exp(-1),3,50*exp(-1), col=\"red\", lty=3)\nsegments(3,50*exp(-1),3,50*exp(-3), col=\"red\", lty=3)\nsegments(4,50*exp(-4),6,50*exp(-4), col=\"red\", lty=3)\nsegments(6,50*exp(-4),6,50*exp(-6), col=\"red\", lty=3)\nsegments(7,50*exp(-7),9,50*exp(-7), col=\"red\", lty=3)\nsegments(9,50*exp(-7),9,50*exp(-9), col=\"red\", lty=3)\n\n\n\n\nCompare them.\n\n# draw exp first to make sure axes fit\nrequire(viridisLite)\n\nLoading required package: viridisLite\n\nc <- plasma(3)\ncurve(quad(x), 0, 10, lwd=3, col=c[1],\n      xlab=\"x\", ylab=\"y\",\n      xaxs=\"i\", yaxs=\"i\")\ncurve(lin(x), 0, 10, lwd=3, col=\"black\", add=TRUE)\ncurve(exp(x), 0, 10, lwd=3, col=c[2], add=TRUE)\ncurve(log(x), 0.01, 10, lwd=3, col=c[3], add=TRUE)\nlegend(\"topleft\", c(\"linear\",\"quadratic\",\"exponential\",\"logarithmic\"),\n       col=c(\"black\",c), lty=1, lwd=3)\n\n\n\n\n\n\n1.3.3 Power Laws\nIt turns out that much of the world – particularly in biology – scales according to a power law. Nearly everything you can imagine measuring about an organism scales with an organism’s body mass and it does so according to a power law. So for some outcome \\(Y\\) (e.g., lifespan, annual fertility, brain mass, metabolic rate, etc.), where we let \\(W\\) indicate body mass, the scaling relationship takes the form\n\\[\nY = A W^a.\n\\]\nIf \\(a>1\\), this curve will be convex (i.e., increasing returns to size), while if \\(0<a<1\\), the curve will be concave. If \\(a=1\\), then we simply have a straight line with slope \\(A\\) and intercept zero. In comparative biology, the case where \\(a=1\\) is known as “isometry” and the case where \\(a \\neq 1\\) is known as “allometry”.\nIf we take logarithms of both sides of the power-law relation, we get a linearized form,\n\\[\n\\log(Y) = \\log(A) + a \\log(W).\n\\]\nPlotting data on double-logarithmic axes can help in diagnosing a power law.\nWhen \\(a<0\\), we have the case of power-law decay. This provides a very interesting case where the decay of some function can be considerably slower than exponential. For example, most of the common probability distributions that we use (e.g., normal, exponential, Poisson, binomial) have “exponential” tails. This means that the probability associated with a particular value decays exponentially as the values move away from the region of highest probability. In contrast, power-law probability distributions can have fat tails, meaning that extreme values are more likely than they would be under a comparable probability distribution with exponential decay.\nThe key difference between a power law and an exponential, which at first glance appear to be quite similar, is that for the power law, the power is constant (\\(x^a\\)) whereas for an exponential, the power is the variable \\(a^x\\) (where we usually use the specific value of \\(a=e\\), where \\(e\\) is the base of the natural logarithm). Note that we’ve already looked at a comparison between exponential growth and power-law growth, when we compared the quadratic (\\(a=2\\)) to the exponential. Let’s look at power-law decay now.\n\ncurve(0.5^x,0, 10, lwd=3, xaxs=\"i\", xlab=\"x\", ylab=\"y\")\ncurve(x^-2, 0, 10, lwd=3, col=\"red\", add=TRUE)\n\n\n\n\nThe power decay starts much higher (it is, in fact, asymptotic to the \\(y\\)-axis) and declines very rapidly. However, while the exponential curve will quickly approach the \\(x\\)-axis (to which it is asymptotic), the red curve will approach it very slowly. For the exponential curve, every \\(x\\)-increment of one reduces the value of \\(y\\) by a half. In contrast, for large values of \\(x\\), every increment contributes a tiny marginal decay. For the exponential \\(0.5^{x+1}/0.5^{x} = 0.5^1=0.5\\) for all values of \\(x\\). The analogous ratio for the power law is lower for low values of \\(x\\). For \\(x=2\\), \\((x+1)^{-2}/x^{-2}=0.44\\), whereas it is 0.98 for \\(x=100\\)."
  },
  {
    "objectID": "interpreting.html#convexity-and-concavity",
    "href": "interpreting.html#convexity-and-concavity",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.4 Convexity and Concavity",
    "text": "1.4 Convexity and Concavity\nThe derivative of a function provides a measure of how fast a function is changing. The second derivative measures how that rate of change itself is changing. In this sense, it measures the curvature of a function.\nMany theoretical models depend on the curvature of functions to make their predictions. A common assumption employed in many theoretical models is that of concavity. A very common use of concavity in theory is when curve hows diminishing marginal returns. The word “marginal” essentially means the derivative, so diminishing marginal returns means that the derivative of the function is getting smaller for larger values of the input.\nThe classic trade-off model for the evolution of virulence relies on the concavity of transmissibility with respect to disease-induced mortality. If virulence produces decreasing marginal transmissibility with respect to disease-induced mortality, then selection will favor intermediate virulence. Denote virulence by \\(x\\). Both transmission and disease-induced mortality are functions of virulence: \\(\\beta(x)\\) and \\(\\delta(x)\\). The fitness measure for the pathogen is, as usual, \\(R_0\\), which we can write as\n\\[\nR_0 = \\frac{\\beta(x)}{\\mu + \\delta(x)},\n\\]\nwhere \\(\\mu\\) is the disease-independent mortality.\nTo find the optimal value of virulence, differentiate with respect to \\(x\\) and solve for \\(dR_0/dx=0\\). Employing the quotient rule for differentiation and doing a little algebra to tidy up, we get:\n\\[\n\\frac{d \\beta(x)}{d \\delta(x)} = \\frac{\\beta(x^*)}{\\mu + \\delta(x^*)},\n\\]\nwhere \\(x^*\\) indicates the optimal value of virulence.\nThe geometric interpretation of this result is that optimal virulence satisfies the condition that a line, rooted at the origin, is tangent to the curve relating transmissibility to mortality. This result is known as the Marginal Value Theorem in behavioral ecology and, in addition to describing a model for optimal virulence, also predicts the optimal length of time for a foraging bout in a feeding patch or the optimal copula duration when a male has multiple mating opportunities but his sperm can be displaced by subsequent matings.\n\nx <- seq(0,30,length=500)\n# transmissibility function fp> 0 fpp < 0\nf <- function(x) {\n  0.5 - exp(-0.2*(x-7))\n}\n# derivative of the utility function\nfprime <- function(x) {\n  0.2*exp(-0.2*(x-7))\n}\n\n# 1st-degree Taylor series around x: f + fp*(z-x) = 0\n# z = x -(f/fp)\n# solve for tangency; find the root of this\nxinter <- function(x) {\n  return(x - f(x)/fprime(x))\n}\n\nsoln <- uniroot(xinter,c(0,40))\nplot(x,f(x), type=\"l\", lwd=2, xaxs=\"i\", yaxs=\"i\",\n     axes=FALSE,\n     xlab=\"Mortality\",\n     ylab=\"Transmissibility\",\n     ylim=c(0,0.7))\naxis(1,labels=FALSE,tick=FALSE)\naxis(2,labels=FALSE,tick=FALSE)\nbox()\nlines(x,(f(soln$root)/soln$root)*x,col=grey(0.75))\nsegments(soln$root,0,soln$root,f(soln$root), lty=2, col=\"red\")\nsegments(0,f(soln$root),soln$root,f(soln$root), lty=2, col=\"red\")\nmtext(expression(paste(delta,\"*\")),1,at=soln$root, padj=1)\nmtext(expression(paste(beta,\"*\")),2,at=f(soln$root),padj=0.5, adj=1.5, las=2)\nmtext(expression(mu),1,at=5, padj=1)\n\n\n\n\nWhat would happen if the function was convex (\\(f''(x)>0\\)), rather than concave? There can be no intermediate optimum for a such a convex function. The optimal virulence is maximum.\nIn one of the most important papers in the field of life history theory, Gadgil and Bossert (1970) noted that the only conditions under which natural selection will favor intermediate reproductive effort are when the fitness gains to effort are concave and, importantly, that the costs of effort are either linear or convex. We can easily visualize why this is the case.\n\nx <- seq(1,11,,110)\ny <- 4*log(x)\ny1 <- 0.1*exp(x/2)\ny2 <- 0.1*exp(x/1.5)\n# maxima\nd1 <- y-y1\nd2 <- y-y2\nmax1 <- x[which(d1==max(d1))]\nmax2 <- x[which(d2==max(d2))]\n\n### concave benefits/concave costs\nplot((x-1)/10,y/11, type=\"l\", lwd=3, \n     xlab=\"Reproductive Effort\", \n     ylab=\"Cost or Benefit\",  \n     xlim=c(0,1), ylim=c(0,1))\nlines((x-1)/10, y/11 + 0.01*x, lwd=3, col=\"red\")\n#legend(0.05,1, c(\"Benefit\",\"Cost\"), lwd=3, lty=1, col=c(\"black\",\"red\"))\nabline(v=0, col=grey(0.65))\ntitle(\"No Reproduction\")\n\n\n\n### concave benefits/convex costs\nplot((x-1)/10,y/11, type=\"l\", lwd=3, \n     xlab=\"Reproductive Effort\", \n     ylab=\"Cost or Benefit\", \n     xlim=c(0,1), ylim=c(0,1))\nlines((x-1)/10,y1/11, lwd=3, col=\"red\")\nabline(v=max1/11, col=grey(0.65))\n#legend(0.05,1, c(\"Benefit\",\"Cost\"), lwd=3, lty=1, col=c(\"black\",\"red\"))\ntitle(\"Intermediate Reproduction\")\n\n\n\n### concave benefits/concave costs, full RE\nplot((x-1)/10,y/11, type=\"l\", lwd=3, col=\"red\", \n     xlab=\"Reproductive Effort\", \n     ylab=\"Cost or Benefit\", \n     xlim=c(0,1), ylim=c(0,1))\nlines((x-1)/10, y/11 + 0.01*x, lwd=3, col=\"black\")\n#legend(0.05,1, c(\"Benefit\",\"Cost\"), lwd=3, lty=1, col=c(\"black\",\"red\"))\nabline(v=1, col=grey(0.65))\ntitle(\"Maximal (Suicidal) Reproduction\")\n\n\n\n\nOnly for the concave benefit/linear cost case does the maximum difference between the curves lie in the middle of the plot.\n\n1.4.1 Concavity Introduces Asymmetries\nSuppose you have a curve representing the fitness, \\(w\\), corresponding to a given level of effort, \\(x\\), similar to the Gadgil-Bossert curves discussed above. Further suppose that this curve is concave, showing diminishing marginal returns so that \\(w'(x)>0\\) and \\(w''<0\\).\nStarting at some point on this curve, say at the mean effort \\(\\bar{x}\\), imagine you flip a coin and get decremented a unit’s worth of fitness if it comes up heads and increase a unit’s worth if it comes up tails. This is known as a lottery, a decision in which there is a discrete, variable payoff. We can plot this as follows:\n\n## risk-aversion\nx <- seq(0,5,length=1000)\nr <- 0.75\nfx <- 1-exp(-r*x)\n## for part deux\naaa <- (fx-0.4882412)^2\nwhich(aaa==min(aaa))\n\n[1] 179\n\n#[1] 179\nplot(x,fx, type=\"n\", lwd=3, axes=FALSE, frame=TRUE,\n     xlab=\"Parity (x)\", ylab=\"Fitness (w(x))\", \n     xaxs=\"i\", yaxs=\"i\", xlim=c(-0.1,5.1), ylim=c(0,1))\n#segments(0,0,5,fx[1000], lwd=2, col=grey(0.75))\naxis(1, at=c(0,2.5,5), labels=c(expression(x[0]), expression(bar(x)),\n                                expression(x[1])), tick=FALSE)\nsegments(2.5,0,2.5,0.846645, lwd=3, lty=1, col=grey(0.65))\nsegments(2.5,0.846645,0,0.846645, lwd=3, lty=1, col=\"red\")\narrows(0,0.846645,0,0.01, lwd=3, lty=1, col=\"red\", length=.25,angle=10)\nsegments(2.5,0.846645,5,0.846645, lwd=3, lty=1, col=\"red\")\narrows(5,0.846645,5,fx[1000], lwd=3, lty=1, col=\"red\", length=.25,angle=10)\nlines(x,fx, lwd=3, col=\"black\")\n\n\n\n\nThe upside of this lottery increases fitness considerably less than the downside reduces it. This arises because of the curvature of the function, in particular, its diminishing marginal fitness returns to effort. This is a very important insight and defines the phenomenon of risk aversion. Risk-aversion in lotteries where the fitness function is a concave function of effort are an application of Jensen’s Inequality, which states that for a concave function, \\(w(x)\\),\n\\[\nw(E(x)) \\geq E(w(x)),\n\\]\nwhere \\(E()\\) indicates mathematical expectation.\nWe can show this graphically. We will draw a chord connecting the upside- and downside-payoffs, the midpoint of which is \\(E(w(x))\\). Note that this is considerably less than \\(w(\\bar{x})\\).\n\nplot(x,fx, type=\"n\", lwd=3, axes=FALSE, frame=TRUE,\n     xlab=\"Parity (x)\", ylab=\"\", \n     xaxs=\"i\", yaxs=\"i\", xlim=c(0,5.1), ylim=c(0,1))\nsegments(0,0,5,fx[1000], lwd=3, col=grey(0.75))\naxis(1, at=c(0.05,x[179],2.5,5), \n     labels=c(expression(x[0]), expression(x[C]),\n               expression(bar(x)), expression(x[1])),\n     tick=FALSE)\nmtext(\"Fitness (w(x))\", side=2,line=2, adj=0.65)\naxis(2, at=0.4882412, labels=\"\", tick=FALSE)\nsegments(2.5,0,2.5,0.4882412,lwd=3, lty=1, col=\"red\") # vertical line at bar(x)\nsegments(2.5,0.4882412,2.5,fx[501], lwd=3, lty=2, col=\"red\")\nlines(x,fx, lwd=3, col=\"black\")\n\n\n\n\nA risk-averse decision-maker should be willing to pay for certainty. We can show why this is graphically. Note that the expected fitness of this lottery (i.e., the average of the two possible outcomes) does not, in fact, fall on the fitness curve. We can move horizontally from this point back to the curve and the fitness would not change. If (and this is a big if) we can achieve certainty in our payoff by paying the difference between \\(E(w(x))\\) and what is called the certainty-equivalent return, we should.\n\nplot(x,fx, type=\"n\", lwd=3, axes=FALSE, frame=TRUE,\n     xlab=\"Parity (x)\", ylab=\"\", \n     xaxs=\"i\", yaxs=\"i\", xlim=c(0,5.1), ylim=c(0,1))\nsegments(0,0,5,fx[1000], lwd=3, col=grey(0.75))\naxis(1, at=c(0.05,x[179],2.5,5), \n     labels=c(expression(x[0]), expression(x[C]),\n              expression(bar(x)), expression(x[1])),\n     tick=FALSE)\nmtext(\"Fitness (w(x))\", side=2,line=2, adj=0.65)\naxis(2, at=0.4882412, labels=\"\", tick=FALSE)\nsegments(2.5,0,2.5,0.4882412,lwd=3, lty=1, col=\"red\") # vertical line at bar(x)\nsegments(2.5,0.4882412,x[179],0.4882412,lwd=3, lty=1, col=\"red\") # horizontal line back to utility curve\nsegments(x[179],0.4882412,x[179],0, lwd=3, lty=1, col=\"green\") # vertical line to x_c\nlines(x,fx, lwd=3, col=\"black\")\ntext(0.35, 0.54, expression(pi==bar(x) - x[C]))"
  },
  {
    "objectID": "interpreting.html#equilibria",
    "href": "interpreting.html#equilibria",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.5 Equilibria",
    "text": "1.5 Equilibria\nIn ecology, evolution, etc., we frequently plot two (or more) sets of rates. For example: birth and death rates in a demographic model or rates of colonization and extinction in a metapopulation model.\nFor example, the classic Levins model for metapopulations\n\\[\n\\dot{n} = cn(1-n) - en,\n\\]\nwhere \\(n\\) is patch occupancy, \\(c\\) is the colonization rate, and \\(e\\) is the extinction rate. The equilibrium for this happens when \\(\\dot{n}=0\\), which is\n\\[\n\\hat{n} = 1 - \\frac{e}{c}.\n\\]\nIf the extinction rate is greater than the colonization rate (\\(e>c\\) ), then, sensibly, the overall population is extinct. Moreover, there will generally always be unoccupied patches at equilibrium.\nA classic example of a graphical representation of such an equilibrium process is the MacArthur-Wilson model, which is similar to the Levins metapopulation model in that it posits the number of species on an island is a dynamic balance between the colonization rate (which declines as a function of the number of resident species) and the extinction rate (which increases as a function of the number of resident species). The equilibrium occurs where the colonization rate just balances out the extinction rate, so that the overall rate of change of species is zero, the definition of an equilibrium.\n\nn <- seq(0,20,,500)\nrate <- 0.2\ncinit <- 55\nplot(n, cinit*exp(-rate*n), type=\"l\", \n     lwd=3, col=\"#0D0887FF\",\n     xlab=\"Number of Species\", \n     ylab=\"Rate\",\n     ylim=c(0,60),\n     xlim=c(-3,23),\n     yaxs=\"i\",\n     axes=FALSE)\nlines(n, exp(rate*n), lwd=3, col=\"#9C179EFF\")\nsegments(log(cinit)/(2*rate),0,log(cinit)/(2*rate),exp(rate*log(cinit)/(2*rate)), lty=2)\naxis(1, at=c(log(cinit)/(2*rate)), labels = c(expression(hat(N))))\nbox()\n\n\n\n\n\n1.5.1 Equilibria in Discrete-Time\nRecursions.\nPoverty-trap model. We plot the wealth at time \\(t+1\\) agains the wealth at time \\(t\\). Use a Prelec weighting function to produce the characteristic S-shape of the poverty-trap model. An equilibrium occurs when the the wealth in the next time step is equal to the wealth in the current time step (i.e., there is no change). In this plot, this occurs wherever our curve touches the line of equality, \\(w_{t+1}=w_t\\).\nThe downside of the Prelec function is that we can’t easily solve for an equilibrium analytically, but we can solve it numerically using uniroot().\n\nprelec <- function(p,a,b) (exp(-(-log(p))^a))^b\n## function to solve for interior equilibrium\nfn <- function(p,a,b) (exp(-(-log(p))^a))^b - p\na <- 2\nb <- 1.7\n# we know p=0 and p=1 are solutions so limit to searching an interior interval\npint <- uniroot(fn,interval=c(0.1,0.9),a=a,b=b)$root\np <- seq(0,1,,1000)\nplot(p, prelec(p=p,a=a,b=b), type=\"l\", col=\"blue4\", lwd=2, \n     axes=FALSE, frame=TRUE,\n     xaxs=\"i\", yaxs=\"i\", \n     xlab=expression(W[t]), ylab=expression(W[t+1]),\n     xlim=c(-0.05,1.05), ylim=c(-0.05,1.05))\nabline(a=0,b=1,lwd=1, col=grey(0.75))\npoints(c(0,pint,1),c(0,prelec(p=pint,a=a,b=b),1), pch=c(19,1,19), cex=1.5)\n\n\n\n\nThere are three equilibria for the poverty-trap model: (1) a stable equilibrium at destitution (\\(w_t=0\\)), (2) an unstable interior equilibrium, and (3) a stable equilibrium at maximum wealth."
  },
  {
    "objectID": "interpreting.html#indifference-curves",
    "href": "interpreting.html#indifference-curves",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.6 Indifference Curves",
    "text": "1.6 Indifference Curves\nWe encounter indifference curves when we consider the case of multi-species epidemics, as described by Holt and colleagues (2003). Suppose there is an infectious disease that can infect multiple species. In order to be above the epidemic threshold, there have to be a certain minimum number of susceptible individuals.\nOn one side of the curve – where the minimum conditions for an epidemic are exceeded – an epidemic is possible. On the other side of the curve, no epidemic is possible. Any combination of species numbers along the isoclines satisfy the conditions equally well. This is why we call them “indifference curves.”\nStart with the trivial case where the two species don’t interact at all. There will be an epidemic if there are either enough of species 1 or of species 2. The region where both species are below their respective thresholds lies inside the rectangular isocline\n\nplot(1:10,1:10, type=\"n\", axes=FALSE, frame=TRUE, xlab=\"Specis 1\", ylab=\"Species 2\")\nsegments(0,6,6,6, lwd=3)\nsegments(6,0,6,6, lwd=3)\naxis(1, at=c(6), labels=c(expression(hat(S)[1])))\naxis(2, at=c(6), las=2, labels=c(expression(hat(S)[2])))\ntext(3,3, \"No Epidemic\")\ntext(7.5,7.5, \"Epidemic\")\n\n\n\n\nNow consider the slightly more interesting case where hosts of different species can substitute for each other. This means that even if the critical threshold for either of the species is reached, there can still be an epidemic. If the pathogen is not well adapted to a generalist-transmission mode, this effect might be quite small. We can call the epidemic isocline that arises from such conditions weakly-interacting.\n\ng <- seq(0,sqrt(1/5),,500)\nh <- sqrt(1-(5*g^2))\nplot(g,h, type=\"l\", axes=FALSE, frame=TRUE, yaxs=\"i\", xaxs=\"i\", \n     ylim=c(0,1.1), xlim=c(0,0.5), lwd=3, \n     xlab=\"Species 1\", ylab=\"Species 2\")\naxis(1, at=c(sqrt(1/5)), labels=c(expression(hat(S)[1])))\naxis(2, at=c(1), las=2, labels=c(expression(hat(S)[2])))\nsegments(0,1,sqrt(1/5),1, lty=3)\nsegments(sqrt(1/5),0,sqrt(1/5),1, lty=3)\ntext(0.2,0.45, \"No Epidemic\")\ntext(0.4,0.9, \"Epidemic\")\n\n\n\n\nI’ve left the non-interacting isocline in this figure to show how, even though species are only interacting weakly, the space in which an epidemic is possible is greater.\nNow consider the case where substitutable.\n\nplot(0:10,0:10, type=\"n\", axes=FALSE, frame=TRUE, \n     yaxs=\"i\", xaxs=\"i\",\n     xlab=\"Specis 1\", ylab=\"Species 2\")\nsegments(0,9,9,0, lwd=3)\naxis(1, at=c(9), labels=c(expression(hat(S)[1])))\naxis(2, at=c(9), las=2, labels=c(expression(hat(S)[2])))\ntext(2.8,2.7, \"No Epidemic\")\ntext(6.7,5.3, \"Epidemic\")\n\n\n\n\nA perfectly substitutable curve is linear. This means if you can substitute one individual of species 2 for one individual of species 1 when species 1 is just below its critical threshold and still get an epidemic, you can substitute one for one at any point along the isocline. Now, the slope might not be unity. Maybe you have to substitute two of species 2 for one of species 1. The key is that ratio of substitution remains the same for any mixture of the two species.\nThings get more interesting when having a mixture of the two species makes it more likely that there will be an epidemic when there is a more event mixture of the two species that when the mixture is toward one of the extremes (i.e., mostly species 1 or mostly species 2). We call such an isocline complementary.\n\nx <- seq(0,10,,1000)\nplot(x, exp(-0.5*x), \n     type=\"n\", \n     axes=FALSE, frame=TRUE, \n     xaxs=\"i\", yaxs=\"i\", \n     xlab=\"Species 1\",\n     ylab=\"Species 2\", \n     xlim=c(2,9), \n     ylim=c(0.02,0.4))\nlines(x,exp(-0.5*x), lwd=3)\nsegments(2,exp(-0.5*2),log(0.02)/-0.5,0.02, lty=3)\naxis(1, at=c(7.859947), labels=c(expression(hat(S)[1])))\naxis(2, at=c(0.36800318), las=2, labels=c(expression(hat(S)[2])))\ntext(3, 0.08755055, \"No Epidemic\")\ntext(5,0.13, \"Epidemic\")\n\n\n\n\nTo see this, we can look at how the rate of substitution happens at different mixtures of the two species. For example, as you approach the extreme of \\(S_1=0\\), it takes increasingly more of \\(S_2\\) to stay above the epidemic threshold. This is obviously also true as we approach the \\(S_2=0\\) extreme as well, but we’ll focus on the \\(S_1=0\\) extreme here. In the middle of the range, a small change in one can be compensated by a small change in the other, making the epidemic threshold easier to achieve in the middle of the species’ population sizes.\n\nx <- seq(0,12,,1000)\nplot(x, exp(-0.5*x), \n     type=\"n\", \n     axes=FALSE, frame=TRUE, \n     xaxs=\"i\", yaxs=\"i\", \n     xlab=\"Species 1\",\n     ylab=\"Species 2\", \n     xlim=c(2,12), \n     ylim=c(0.002,0.4))\nlines(x,exp(-0.5*x), lwd=3)\nsegments(2.1,exp(-0.5*2.1),2.1,exp(-0.5*2.6), lwd=2, col=\"red\")\nsegments(2.1,exp(-0.5*2.6),2.6,exp(-0.5*2.6), lwd=2, col=\"red\")\nsegments(5,exp(-0.5*5),5,exp(-0.5*5.5), lwd=2, col=\"red\")\nsegments(5,exp(-0.5*5.5),5.5,exp(-0.5*5.5), lwd=2, col=\"red\")"
  },
  {
    "objectID": "interpreting.html#plotting-tricks",
    "href": "interpreting.html#plotting-tricks",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.8 Plotting Tricks",
    "text": "1.8 Plotting Tricks\nI have a whole other set of notes on how to produce scientific figures in R. However, I’ve repeatedly done some things in these notes that merit a brief explanation. Otherwise, there is a risk of things seeming obscure and generally confusing.\nTheoretical plots usually don’t depend on specific values of inputs or functions – you’re typically care just about the shapes and not the specific values. You are trying to show the general behavior of your system. R is a statistical programming language and, as such, expects you to be plotting data. Presumably, you care about the actual values when data are involved. For our theoretical plots, we usually want to suppress the values on the plot’s axes. This is why nearly all of these figures include the arguments to the plot() command axes=FALSE and frame=TRUE. This suppresses the axes and any ticks and labels indicating specific values on them. We can then add in custom axis labels, such as the critical population size for each species in the multi-species epidemic isoclines using the command axis().\nPerhaps a more mysterious tick I use is to include the arguments xaxs=\"i\" and yaxs=\"i\". This is really the special sauce of a scientific-theory plot in R. Again, R expects data when you call the plot() command. A good aesthetic practice for data plots is to pad the range of the observed data and R does this by default. By forcing the style of the axes to be “internal” (that’s what the “i” stands for), you restrict the axes to the range of your data. This means that \\(y\\)-intercepts actually intercept the \\(y\\) axis, curves that should start at zero actually look like they’re starting at zero, etc.\nWe often want to lay out the axes but not draw a curve quite yet. To do this, we add the argument type=\"n\" to the plot() command. This allows us to build up complex figures with more precision and control. You might notice that we often plot the actual curve we care about last. This is because we want it on top of the various lines we’ve added to indicate interesting bits of the curve (e.g., equilibria and such).\n\n\n\n\nGadgil, Madhav, and William H. Bossert. 1970. “Life Historical Consequences of Natural Selection.” The American Naturalist 104 (935): 1–24. http://www.jstor.org/stable/2459070."
  },
  {
    "objectID": "odes.html#lotka-volterra-model",
    "href": "odes.html#lotka-volterra-model",
    "title": "4  ODEs in R",
    "section": "4.1 Lotka-Volterra Model",
    "text": "4.1 Lotka-Volterra Model\nThe Italian biologist Humberto D’Ancona noted that during the first World War, the composition of fish in the markets around the Adriatic Sea changed substantially. During the war, the percentage of predatory fish for sale in the markets of Trieste, Fiume, and Venice increased. D’Ancona had no explanation for this and approached his father-in-law, the eminent mathematician Vito Volterra, with the riddle. Volterra’s solution forms the foundation for nearly all subsequent theory regarding the interaction of species within communities. The great American biologist and demographer, Alfred Lotka, developed the same framework about the same time and the equations have since been known as the Lotka-Volterra model for predatory/prey dynamics.\nThe classical theory of species interactions is attributable to Alfred Lotka and Vito Volterra involves reducing communities to a single consumer-resource relationship – typically between a primary consumer (i.e., a herbivore) and a secondary consumer (i.e., a carnivore).\nThe assumptions of Lotka-Volterra model include: - in the absence of a predator, the prey population increases exponentially - in the absence of prey, the predator population decays exponentially - per capita rate of kill a linear function of prey density - each kill contributes equally to predator growth\n\nrequire(deSolve)\nlv <- function(t, x, parms) {\n  with(as.list(parms), {\n    dx1 <- r1*x[1] - c1*x[1]*x[2]\n    dx2 <- -r2*x[2] + c2*x[1]*x[2]\n    results <- c(dx1,dx2)\n    list(results)\n  })\n}\n\nxstart <- c(x1=10,x2=1)\ntimes <- seq(0,100,length=1001)\nparms <- c(r1=0.5,r2=0.5, c1=0.1,c2=0.02)\nout1 <- as.data.frame(ode(xstart,times,lv,parms))\n\nwith(out1, plot(time, x1, type=\"l\", lwd=3, col=\"red\", \n                xlab=\"Time\", ylab=\"Population Size\", xlim=c(0,100), ylim=c(0,90)))\nwith(out1, lines(time, x2, ,lwd=3, col=\"blue\"))\nlegend(\"topleft\",c(\"prey\",\"predator\"), lwd=3, col=c(\"red\",\"blue\"))\n\n\n\nwith(out1, plot(x1, x2, type=\"l\", col=\"magenta\", lwd=3, xlab=\"Prey Population Size\", ylab=\"Predator Population Size\",\n                xlim=c(0,90), ylim=c(0,20)))\n\n\n\n\n\n4.1.1 Rosenzweig-MacArthur\nRosenzweig and MacArthur (1963) include two elements of ecological realism in their extension of the classic Lotka-Volterra model. First, they include density-dependence of the prey population. The growth of the prey population in the absence of the predator is no longer exponential, but is now a function of current size of the population, with a fixed upper limit to total prey population size. Second, the kill rate of predators is no longer linear. Predators have a functional response to prey abundance. In particular, the number of prey harvested by predators saturates, reflecting the eventual satiation of the predators. Here, I present slightly modified code for the Rosenzsweig-MacArthur model presented in Stevens (2009).\n\nrequire(deSolve)\n### Lotka-Volterra with Type II Functional Response\n# Rosenzweig & MacArthur (1963) model\npredpreyRM <- function(t, y, p) {\n  H <- y[1]\n  P <- y[2]\n  with(as.list(p), {\n    dH <- b*H * (1 - alpha*H) - w*P*H/(D+H)\n    dP <- e*w*P*H/(D+H) - s*P\n    return(list(c(dH, dP)))\n  }) \n}\nb <- 0.8\ne <- 0.07\ns <- 0.2\nw <- 5\nD <- 400\nalpha <- 0.001\nH <- 0:(1/alpha)\n\n\nHiso <- expression(b/w * (D + (1 - alpha * D) * H - alpha * H^2))\nHisoStable <- eval(Hiso)\n\np.RM <- c(b = b, alpha = alpha, e = e, s = s, w = w, D = D)\ntmax <- 150\ntimes <- seq(0,tmax,by=0.1)\nRM1 <- as.data.frame(ode(c(900, 120), times, predpreyRM, p.RM))\ncolnames(RM1) <- c(\"time\",\"prey\",\"predator\")\n\nplot(RM1[,\"time\"], RM1[,\"prey\"], type=\"l\", lwd=2, col=\"blue\", xaxs=\"i\",\n     xlab=\"Time\", ylab=\"Population Size\",\n     ylim=c(0,900))\nlines(RM1[,\"time\"], RM1[,\"predator\"], col=\"orange\", lwd=2)\nlegend(\"topright\",c(\"Predator\",\"Prey\"), col=c(\"orange\",\"blue\"),lwd=2)\n\n\n\n\nNo more cycles!"
  },
  {
    "objectID": "odes.html#sir-model",
    "href": "odes.html#sir-model",
    "title": "4  ODEs in R",
    "section": "4.2 SIR Model",
    "text": "4.2 SIR Model\nWe start with a simple Susceptible-Infeced-Recovered (SIR) epidemic. The SIR epidemic is a system of three coupled ODEs.\n\nSimple model for a closed-population (i.e., no births or deaths)\nNeed to write a function that encodes the system of equations\nThe function takes three arguments t, x, and parms\n\nthese are the time over which the equations are integrated, the state values (i.e., S,I, and R), and the model parameters\n\nThe function starts by renaming the elements of the state vector x as things that make the equations easier to read – e.g., I instead of x[2]\nThe line with(as.list(parms) can take some unpacking\n\nUsing with() means setting up a local scope for variables\nas.list() coerces our vector of parameters into a list\nthese two elements allow us to write the equations in a simple and readable way\nNote we don’t have to say something like parms[\"beta\"] or parms[3] in order to use that parameter in our equation\n\n\n\nrequire(deSolve)\nsir <- function(t,x,parms){\n    S <- x[1]\n    I <- x[2]\n    R <- x[3]\n  with(as.list(parms),\n{\n    dS <- -beta*S*I\n    dI <- beta*S*I - nu*I\n    dR <- nu*I\n    res <- c(dS,dI,dR)\n  list(res)\n})\n}\n\n\nIn order to integrate the equations, use the function lsoda() (which is the solver we use) or ode() (which is a wrapper for different types of solvers including lsoda)\nWe pass the solver the initial state vector, the times, the name of our function that describes the system of equations, and the vector of parameters\nThe solver will return the solutions as a matrix; we coerce this using data.frame() to make it easier to work with, plot, etc.\nOnce we have the data frame, we name the columns to make them easier to refer to\n\n\nN <- 1e4\nparms <- c(N=N,beta=0.0001, nu = 1/2.5)\ntimes <- seq(0,50,0.1)\nx0 <- c(N-1,1,0)\nstateMatrix <- as.data.frame(lsoda(x0,times,sir,parms))\n\ncolnames(stateMatrix) <- c(\"time\",\"S\",\"I\",\"R\")\nplot(stateMatrix[,\"time\"], stateMatrix[,\"S\"], type=\"l\", lwd=2, col=\"blue\",\n     ylim=c(0,1e4),\n     xlab=\"Time\", ylab=\"Population Size\")\nlines(stateMatrix[,\"time\"], stateMatrix[,\"I\"], col=\"red\", lwd=2)\nlines(stateMatrix[,\"time\"], stateMatrix[,\"R\"], col=\"green\", lwd=2)\nlegend(\"right\", c(\"S\",\"I\",\"R\"), col=c(\"blue\",\"red\",\"green\"), lwd=2)\n\n\n\n\nPlot the phase portrait.\n\nplot(stateMatrix[,\"S\"], stateMatrix[,\"I\"], type=\"l\", lwd=2, col=\"blue\",\n     xlab=\"Susceptible\", ylab=\"Infected\")"
  },
  {
    "objectID": "odes.html#measles-model",
    "href": "odes.html#measles-model",
    "title": "4  ODEs in R",
    "section": "4.3 Measles Model",
    "text": "4.3 Measles Model\n\n\n\nState diagram for the SEIR model.\n\n\n\nSusceptible, Exposed, Infected, Recovered (SEIR) model\nUse parameterization from Ottar Bjornstad (a.k.a., “The Measles Man”)\nOpen population of constant size (birth rate = death rate (\\(\\mu\\)))\nInclude vaccinated fraction \\(p\\)\nModel is a damped oscillator\n\nBased on this parameterization, what is the life expectancy of individuals in the population? How long is the latent period? How long are cases infectious?\n\nseir <- function(t,x,parms){\n    S <- x[1]\n    E <- x[2]\n    I <- x[3]\n    R <- x[4]\n  with(as.list(parms),{\n    dS <- mu*(N*(1-p)-S) - beta*S*I/N\n    dE <- beta*S*I/N - (mu + sigma)*E\n    dI <- sigma*E-(mu+gamma)*I\n    dR <- gamma*I-mu*R+ mu*N*p\n    res <- c(dS,dE,dI,dR)\n    list(res)\n  })\n}\n\ntimes <-  seq(0, 30, by = 1/52)\nparms <-  c(mu = 1/75, N = 1, p = 0, beta = 1250, sigma = 365/7, gamma = 365/7)\nxstart = c(S = 0.06, E = 0, I = 0.001, R = 0)\nstateMatrix <-  as.data.frame(lsoda(xstart, times, seir, parms))\n##\ncolnames(stateMatrix) <- c(\"time\",\"S\",\"E\", \"I\",\"R\")\nplot(stateMatrix[,\"time\"], stateMatrix[,\"I\"], type=\"l\", lwd=2, col=\"blue\",\n     xlab=\"Time\", ylab=\"Fraction Infected\")\n\n\n\n\nSpiralize! (i.e., plot the phase portrait)\n\nplot(stateMatrix[,\"S\"], stateMatrix[,\"I\"], type=\"l\", lwd=2, col=\"blue\",\n     xlab=\"Susceptible\", ylab=\"Infected\")\n\n\n\n\nCalculate the power spectrum. We’ll trim the plot for all periods greater than 2.5 yrs, since the power is essentially zero for all such periods.\n\nspec <- spectrum(stateMatrix$I, log=\"no\", spans=c(2,2), plot=FALSE)\ndelta <- 1/52\nplot(spec$freq[1:84]/delta, 2*spec$spec[1:84], type=\"l\", lwd=2, col=\"red\", xlab=\"Period\", ylab=\"Spectrum\")\n\n\n\nfmax <- which(spec$spec==max(spec$spec))\n1/spec$freq[fmax]\n\n[1] 123.0769"
  },
  {
    "objectID": "odes.html#lorenz-attractor",
    "href": "odes.html#lorenz-attractor",
    "title": "4  ODEs in R",
    "section": "4.4 Lorenz Attractor",
    "text": "4.4 Lorenz Attractor\nThe Lorenz Attractor is a classic model for dynamical systems and I include it to give you another example of numerically integrating a system of equations in deSolve.\n\nlorenz <- function(t, state, p) {\n    with(as.list(c(state, parms)), {\n\n        dx <- sigma*(y - x)\n        dy <- x*(rho - z) - y\n        dz <- x*y - beta*z\n\n        list(c(dx, dy, dz))\n    })\n}\n\nparms <- c(sigma=10, beta=8/3, rho=28)\ny0 <- c(x = 1, y = 1, z = 1)\ny0p <- y0 + c(1e-6, 0, 0)\ntimes <- seq(0, 100, 0.01)\n\nout <- ode(y = y0, times = times, func = lorenz, parms = parms)\nout2 <- ode(y = y0p, times = times, func = lorenz, parms = parms)\n\nplot(out[,\"x\"], out[,\"y\"], type=\"l\", lwd=0.25, main = \"Lorenz butterfly\", xlab = \"x\", ylab = \"y\")\n\n\n\nplot(out[,\"x\"], out[,\"z\"], type=\"l\", lwd=0.25, main = \"Lorenz butterfly\", xlab = \"x\", ylab = \"z\")\n\n\n\nplot(out[,\"y\"], out[,\"z\"], type=\"l\", lwd=0.25, main = \"Lorenz butterfly\", xlab = \"y\", ylab = \"z\")\n\n\n\n\n\n\n\n\nRosenzweig, M. L., and R. H. MacArthur. 1963. “Graphical Representation and Stability Conditions of Predator-Prey Interactions.” The American Naturalist 97 (895): 209–23. https://doi.org/10.1086/282272.\n\n\nStevens, M. Henry. 2009. A Primer of Ecology with r. Edited by M. HenryH Stevens. New York: Springer. https://doi.org/10.1007/978-0-387-89882-7."
  },
  {
    "objectID": "drawing.html#numerical-derivative-for-equilibria-and-tangent-lines",
    "href": "drawing.html#numerical-derivative-for-equilibria-and-tangent-lines",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.6 Numerical Derivative for Equilibria and Tangent Lines",
    "text": "2.6 Numerical Derivative for Equilibria and Tangent Lines\nWe can recreate the figures from May’s classic paper on how simple population models can yield very complex dynamics (May 1976). May investigates the logistic map, a first-order difference equation. The logistic map is essentially a discrete-time density-dependent model.\n\\[\nX_{t+1} = aX_t(1 -X_t),\n\\]\nwhere \\(X_t\\) is the state of the population (e.g., its size) at time \\(t\\) and \\(a\\) is the per-period multiplicative growth rate in the absence of any density effect. May (1976) shows that when \\(a>3\\), this model becomes unstable about its fixed point and when\n\n# logistic map\nlmap <- expression(a*x*(1-x))\nx <- seq(0,1,,1000)\n\n### first plot the unstable recruitment curve\na <- 3.414\nx1 <- eval(lmap)\nplot(x,x1, type=\"l\", lwd=2, \n     xaxs=\"i\", yaxs=\"i\", ylim=c(0,1),\n     xlab=expression(X[t]),ylab=expression(X[t+1]))\n\n## equilibrium for logistic map\nxstar1 <- 1-(1/a)\n\n## numerical derivative\nx1p <- diff(x1)\nxp <- diff(x)\n### the equilibrium x is approximately x[706]\nm1 <- x1p[706]/xp[706]\n\n### use point-slope eq for a line y - y_1 = m(x - x_1)\n### we know the point (xstar,xstar) so solve for eq we can use to draw line\nlines(x[550:850], m1*x[550:850]-m1*xstar1+xstar1,lty=2)\n\n### now plot the stable recruitment curve\na <- 2.707\nx2 <- eval(lmap)\nlines(x,x2, lwd=2, col=grey(0.75))\nxstar2 <- 1-(1/a)\nx2p <- diff(x2)\nxp <- diff(x)\n### the equilibrium x is approximately x[700]\nm2 <- x2p[630]/xp[630]\nlines(x[480:780], m2*x[480:780]-m2*xstar2+xstar2,lty=2)\nabline(a=0,b=1)\nlegend(\"topleft\", c(\"a=2.707\", \"a=3.414\"), col=c(grey(0.75), \"black\"), lwd=2)\n\n\n\n\nThe slope on the black curve at the fixed point is steeper than \\(-45^{\\circ}\\) so the fixed point for this higher-growth model is unstable, while the slope at the fixed point for the grey curve is shallower than \\(-45^{\\circ}\\) and is therefore stable.\nNaturally, we could have actually calculated the derivatives of the recruitment function, but this hack actually works pretty well. You just need to make sure that your \\(x\\) values are fine-grained enough that the numerical derivative is approximately right.\n\n2.6.1 Why Period Doubling\nMay (1976) shows how plotting the iterated map can help us understand the phenomenon of period-doubling.\n\nlmap3 <- expression(a*(a*(a*x*(1-x))*(1-(a*x*(1-x))))*(1-(a*(a*x*(1-x))*(1-(a*x*(1-x))))))\na <- 3.7\nx3 <- eval(lmap3)\nplot(x,x3, type=\"l\",lwd=2,\n     xaxs=\"i\", yaxs=\"i\",\n     ylim=c(0,1),\n     xlab=expression(X[t]),ylab=expression(X[t+3]))\na <- 3.9\nlines(x,eval(lmap3), lwd=2, col=grey(0.75))\nlines(x,x)\n\n\n\n\nThe black curve is only intersected by the line of equality once, indicating that there is a single period-3 cycle for \\(a=3.7\\). However, when we raise the growth rate to \\(a=3.9\\), the hills and valleys become much steeper and six more period-3 cycles appear!"
  },
  {
    "objectID": "drawing.html#bifurcation-diagram",
    "href": "drawing.html#bifurcation-diagram",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.7 Bifurcation Diagram",
    "text": "2.7 Bifurcation Diagram\nMay (1976) logistic map. There is a doubling of the period of the time series at \\(a=3\\). At \\(a=3.57\\), cycles of period \\(2^n\\) begin to appear. At \\(a=3.68\\), period-3 cycles appear, and at \\(a=3.83\\), every integer period is present. We can show this using a bifurcation diagram, which shows the different values of \\(X\\) that the population will cycle between for various values of \\(a\\). For values of \\(a<3\\), the equilibrium is stable, so there is only a line.\n\nn <- 1\nR <- seq(2.5,4,length=1000)\nf <- expression(a*x*(1-x))\ndata <- matrix(0,200,1001)\n\nfor(a in R){\n  x <- runif(1) # random initial condition\n  ## first converge to attractor\n  for(i in 1:200){\n    x <- eval(f)\n  } # collect points on attractor\n  for(i in 1:200){\n    x <- eval(f)\n    data[i,n] <- x\n  }\n  n <- n+1\n}\n\ndata <- data[,1:1000]\nplot(R,data[1,], pch=\".\", xlab=\"a\", ylab=\"X\")\nfor(i in 2:200) points(R,data[i,], pch=\".\")"
  },
  {
    "objectID": "drawing.html#using-expression-to-draw-functional-response-curves",
    "href": "drawing.html#using-expression-to-draw-functional-response-curves",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.3 Using expression() to Draw Functional-Response Curves",
    "text": "2.3 Using expression() to Draw Functional-Response Curves\nThere are several different ways that you can draw a theoretical curve. In the last chapter, I used curve() to draw many of the figures. I find that I have better control over the overall figure, however, if I can access the equation and its evaluation more directly. The quick-and-dirty way to do this is to write an expression(). An expression is an object whose evaluation is delayed until explicitly called for with the function eval(). So you can define your equation of theoretical interest, then enter its inputs, and then evaluate it when it is convenient for you (e.g., when you’re plotting).\nWe can demonstrate this functionality by comparing the Holling family of functional-response curves. These curves model, among other things, the satiation of a predator as prey density increases.\nThe most commonly-used of these functional responses is certainly Holling Type II, which is also known (e.g., in physiology) as the Michaelis–Menten function, which is a simple, if ubiquitous, model of enzyme kinetics.\n\nx <- seq(0,10, length=200)\na <- 0.7\nb <- 1.5\nc <- -1.5\nh2 <- expression(a*x/(1 + a*x))\nh3 <- expression(a*x^2/(b^2+x^2))\nh4 <- expression(a*x^2/(b+c*x+x^2))\n#\nplot(x, eval(h4), type=\"l\", lwd=3, col=\"magenta\",  xaxs=\"i\", yaxs=\"i\", axes=FALSE, xlab=\"Abundance\", ylab=\"Response\", ylim=c(0,1.2))\nlines(x,eval(h3), lwd=3, col=\"cyan\")\nlines(x, eval(h2), lwd=3, col=\"black\")\nlegend(\"topright\", c(\"Type II\", \"Type III\", \"Type IV\"), col=c(\"black\",\"cyan\",\"magenta\"), lwd=3)\nbox()\n\n\n\n\nGraphics Tip: We add a legend to a figure, not surprisingly, with the function legend(). The first argument to legend() is its location. You can specify this with x,y-coordinates or, more simply, with a keyword from the list that includes: “bottomright”, “bottom”, “bottomleft”, “left”, “topleft”, “top”, “topright”, “right” and “center”. Sometimes you need to fiddle around with the location of the legend as it might appear quite different under different graphics devices (e.g., in the Plots window of RStudio vs. a .png file vs. a .pdf file)."
  },
  {
    "objectID": "drawing.html#s-shaped-curves",
    "href": "drawing.html#s-shaped-curves",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.10 S-Shaped Curves",
    "text": "2.10 S-Shaped Curves\nThere are numerous instances where we want to draw S-shaped curves. For example, we might want to show density-dependent population growth or the fraction of a population who have adopted an innovation.\nThere are a number of ways to draw S-shaped curves. The first is to use a logistic function.\nAnother possibility is to use a cumulative distribution function for a normal random variable.\nHere is an example of an adoption curve (E. M. Rogers 2003).\n\n## stylized adoption curve\nx <- seq(-4,4,,500)\nq <- c(0.025, 0.16, 0.5, 0.84)\nqq <- qnorm(q)\ndd <- dnorm(qq)\nzz <- rep(0,4)\n\nplot(x, dnorm(x), type=\"n\", axes=FALSE, frame=TRUE,\n     xaxs=\"i\", yaxs=\"i\",\n     xlab=\"Time\", ylab=\"Fraction Adopting\", ylim=c(0,1.05))\naxis(2)\nsegments(qq,zz,qq,dd, lwd=3, col=rgb(1,0,0,0.5))\nlines(x, dnorm(x), lwd=3, col=grey(0.65))\nlines(x,pnorm(x), lwd=3)\nlegend(\"topleft\",c(\"incident\",\"cumulative\"),lwd=3, col=c(grey(0.65),\"black\"))\n\n\n\n\n\n2.10.1 Polygyny Threshold Model\nAnother application of S-shaped curves in behavioral ecology is the Polygyny Threshold Model (Orians 1969).\n\n## Polygyny Threshold\nlogisfun <- function(n0=1,K=100,r=0.05,t,delay=0) n0*exp(r*(t-delay))/((1+n0*(exp(r*(t-delay))-1)/K))\n\nt <- seq(0,250,,500)\ndelay <- 50\nn0 <- 1\nK <- 100\nr <- 0.05\n\ny1 <- logisfun(t=t)\ny2 <- logisfun(t=t, delay=50)\n\nplot(t,y1/100, type=\"l\", lwd=3, col=\"magenta\",\n     axes=FALSE, frame=TRUE,\n     xaxs=\"i\", yaxs=\"i\",\n     ylab=\"Female Reproductive Success\", xlab=\"Resource-Holding Capacity\")\nlines(t,y2/100, col=\"purple\", lwd=3)\nsegments(150,0,150,0.6,lty=3)\nsegments(100,0,100,0.6, lty=3)\nsegments(150,0.6,0,0.6,lty=3)\nmtext(expression(Delta[RHC]),1, at=125, col=\"red\")\naxis(1,at=c(100,150), labels=FALSE, col=\"red\")\ntext(177,0.6, expression(RS[S]==RS[P]), col=\"red\")\nlegend(\"topleft\",c(\"primary\",\"secondary\"), lty=1, lwd=3, col=c(\"magenta\",\"purple\"))\n\n\n\n\nThe fitness of the secondary mate is lower for all resource levels except the very highest. If the quality of an already-mated male’s territory is greater than an unmated male’s territory by \\(\\Delta_{RHC}\\), then the fitness of the secondary female is greater than the fitness of a primary female mated to the male with the lower-quality territory. As a result, we expect a polygynous mating.\nFor a quick-and-dirty solution, it is convenient to just represent some equation of interest as an expression(), define some parameters, and then get the function’s values by using eval(). In most cases, it is going to be better to write a function for your equation. In this case, it allowed us to find values for FRS from the two logistic curves associated with specific values of RHC. While it might be a bit more work to write a function, it will probably save effort in the long run. I often prototype plots using expression() and then write a function once I’ve worked out the general features of the plot."
  },
  {
    "objectID": "drawing.html#evolutionary-stable-strategies",
    "href": "drawing.html#evolutionary-stable-strategies",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.11 Evolutionary Stable Strategies",
    "text": "2.11 Evolutionary Stable Strategies\n\n2.11.1 Rogers Paradox\nSelection doesn’t necessarily increase mean fitness (A. R. Rogers 1988). Different Rogers.\n\n## Figure 1 from Rogers (1988)\nwi <- function(b=1,c=0.9) 1 + b*(1-c)\nws <- function(b=1,s=0,p,u=0.8) 1 + (b*(1-s)*(1-p)*(1-u))/(1 - p*(1-u))\n\np <- seq(0,1,,100)\n\ncult <- ws(p=p)\nacult <- rep(wi(),100)\nm <- cult*p + acult*(1-p)\n\nplot(p,cult, type=\"l\", lwd=2, axes=FALSE, frame=TRUE,\n     xaxs=\"i\",\n     xlab=\"Frequency of Social Learning (p)\", ylab=\"Fitness\")\nlines(p,acult, col=\"red\",lwd=2)\nlines(p,m, col=grey(0.75), lty=2,lwd=2)\naxis(1)\nlegend(\"topright\", c(\"individual\",\"social\",\"mean\"), \n       col=c(\"red\",\"black\",grey(0.75)), lty=c(1,1,2))\n\n\n\n\n\n\n2.11.2 Producer-Scrounger Game\n\np1 <- seq(0,1,,200)\nwthief <- expression(1.5 - 2*p1)\nwfarmer <- expression(1 - 1.2*p1)\n\nplot(p1, eval(wthief), type = \"l\", col=\"red\", lwd=2,\n     axes=FALSE, frame=TRUE,\n     xaxs=\"i\", yaxs=\"i\",\n     xlab=\"Fraction Scroungers\", ylab = \"Fitness\", \n     xlim=c(0,1), ylim=c(0,2))\nlines(p1, eval(wfarmer), lwd=2, col=\"blue\")\nlines(p1,(p1*eval(wthief)+(1-p1)*eval(wfarmer)), lwd=2, lty=2)\naxis(1,at=c(0,1),labels=c(\"0\",\"1\"))\nabline(v=0.625, col=grey(0.75), lwd=1)\narrows(0.4,1.5,0.62,1.5,  col=grey(0.75),lwd=2)\narrows(0.8,1.5,0.63,1.5,  col=grey(0.75),lwd=2)\nlegend(\"topright\", c(\"Scrounger\",\"Producer\",\"Mean\"), \n       col=c(\"red\",\"blue\",\"black\"), lwd=2, lty=c(1,1,2))\naxis(3,at=0.625,labels=c(\"ESS\"))\n\n\n\n\nDraw arrows to show the equilibrium and its stability.\nGraphics Tip: Note how we marked the location of the ESS on the top of the plot using axis(3)!"
  },
  {
    "objectID": "drawing.html#prey-choice-model",
    "href": "drawing.html#prey-choice-model",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.12 Prey-Choice Model",
    "text": "2.12 Prey-Choice Model\n\nx <- seq(0,20,length=500)\nf <- function(x,b) {\n  1 - exp(-b*(x-1))\n}\n\nf1 <- function(x,a) a/x\n\nplot(x,f(x,b=0.1), type=\"l\", lwd=3, xaxs=\"i\", yaxs=\"i\",\n     axes=FALSE,\n     xlab=\"Item Rank\",\n     ylab=\"Energy Gain\",\n     ylim=c(0,1))\naxis(1)\nbox()\nlines(x,f(x,b=0.05), lwd=3, col=\"red\")\nlines(x,f1(x,a=2), lwd=3, col=\"grey\")\n# found approximate points using locator()\ntext(2.9,0.9648077,expression(E/h))\ntext(18.75,0.8848253,expression(E^g/t))\ntext(18.75,0.6362313,expression(E^b/t))\nsegments(5.5,0,7.4,0, lwd=10, col=\"green\", lend=2) \ntext(6.45,0.04825, \"Fallback Foods\")\n\n\n\n\nIn a bad year, diet breadth expands. The extent of this expansion is indicated by the green bar."
  },
  {
    "objectID": "drawing.html#extreme-value-distribution-for-innovation",
    "href": "drawing.html#extreme-value-distribution-for-innovation",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.14 Extreme-Value Distribution for Innovation",
    "text": "2.14 Extreme-Value Distribution for Innovation\nInnovation happens when the skill of some learner exceeds the current highest level of skill. The distribution for extreme values like this is know, oddly enough, as an extreme value distribution. There are a number of specific flavors of such distributions.\nHenrich (2004) suggests that the specific EVD for the highest skill is a Gumbel distribution (a type of extreme-value distribution). The level of skill that improves culture is \\(z_h\\). The probability that there will be models with skill level \\(z_h\\) or better is small in smaller populations because this value is out in the tail of the distribution.\nTwo parameters: \\(\\alpha\\) (difficulty) and \\(z\\) (skillfulness), which are assumed independent.\n\n# extreme-value distribution package\nlibrary(evd)\nx <- seq(0,100,,500)\n\nplot(x,dgumbel(x,30,10), type=\"l\", lwd=3, axes=FALSE, frame=TRUE,\n     xlab=expression(paste(\"Learner's Skill, \", z[i])), \n     ylab=expression(paste(\"Probability of Acquiring \", z[i])))\nlines(x,dgumbel(x,30,15), col=\"magenta\", lwd=3)\nabline(v=60,lty=2)\nmtext(expression(z[h]),1, at=60, padj=1)\n\n\n\n\nNote that in the more-innovative population, far more individuals exceed the critical threshold \\(z_h\\), but also way more people are clearly bad at the skill.\nThis result flows precisely from the assumption that learner’s skill follows a Gumbel distribution (i.e., Henrich 2004). It is perfectly fair to ask if this is a reasonable model, but we do know that innovation cultures make a lot of mistakes."
  },
  {
    "objectID": "drawing.html#the-right-ibis",
    "href": "drawing.html#the-right-ibis",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.15 The Right Ibis",
    "text": "2.15 The Right Ibis\nLeslie and Winterhalder (2002) describe a bespoke utility function they call the right ibis model. We can code that and then use it to illustrate Tainter’s model of social collapse.\n\nribis <- function(x,m,n,r){\n  if(x<0 | x>=r){\n    ibis <- 0\n  }\n  if(x>=0 & x<m) {\n    ibis <- exp(m^2/((m-n)^2) - (m*x/(m-n)^2)) * x^(m^2/((m-n)^2)) *\n      m^(-m^2/(m-n)^2)\n  }\n  if(x>=m & x<r){\n    ibis <-  1-(x-m)^2/(m-r)^2\n  }\n  return(ibis)\n}\n\nm <- 8\nn <- 2\nr <- 18\nx <- 0:16\n### Use Right Ibis for Tainter plot\n## plot a nice smooth curve\ny <- seq(0,16,length=100)\naaa <- rep(0,100)\nfor(i in 1:100) aaa[i] <- ribis(x=y[i],m=m,n=n,r=r)\n\nmc <- ribis(x=8,m=m,n=n,r=r)\ndb <- ribis(x=15,m=m,n=n,r=r)\ncl <- ribis(x=2.895,m=m,n=n,r=r)\n\nplot(y,aaa,type=\"l\", lwd=2, axes=FALSE, frame=TRUE,\n     xaxs=\"i\", yaxs=\"i\",\n     ylim=c(0,1.1),\n     xlab=\"Complexity\", ylab=\"Benefits to Complexity\")\nsegments(8,mc,0,mc,lty=3)\nsegments(8,0,8,mc,lty=3)\n\nsegments(15,db,0,db,lty=3, col=\"red\")\nsegments(15,0,15,db,lty=3, col=\"red\")\n#segments(2.895,cl,0,cl,lty=3, col=\"red\")\nsegments(2.895,0,2.895,cl,lty=3, col=\"red\")\n#mtext(expression(paste(B, \"*\")),2, at=mc, adj=1, las=2)\nmtext(expression(B[max]),2, at=mc, adj=1, las=2)\nmtext(expression(B[mid]),2, at=db, adj=1, las=2)\nmtext(expression(C[lo]),1, at=2.895, padj=1)\nmtext(expression(C[opt]),1, at=8, padj=1)\nmtext(expression(C[hi]),1, at=15, padj=1)"
  },
  {
    "objectID": "drawing.html#autocorrelated-time-series",
    "href": "drawing.html#autocorrelated-time-series",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.16 Autocorrelated Time Series",
    "text": "2.16 Autocorrelated Time Series\nSometimes you want to plot a time series for illustrative purposes. More interesting time series, like most actual biophysical series, are likely to show some positive autocorrelation. The AR(1) model is simple model that can produce interesting plots. It is the simplest of the autoregressive models, where the state in the present depends only on the state in the previous time step. A\n\\[\nX_{t+1} = \\varphi X_t + \\varepsilon_t\n\\]\nThe parameter \\(\\varphi\\) is the autocorrelation coefficient and \\(\\varepsilon_t\\) is the shock or “innovation” at time \\(t\\), which is taken to be \\(\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)\\).\nWe might use this model to represent volatile income of an individual hunter:\n\nac1fun <- function(xo,alpha,sigma,tmax){\n  x <- rep(0,tmax+1)\n  x[1] <- xo\n  rr <- rnorm(tmax,0,sigma)\n  for(i in 2:(tmax+1)) x[i] <- alpha*x[i-1] + rr[i-1]\n  return(x)\n}\n\n## xo = initial size\n## alpha = autocorrelation\n## sigma = sd of Gaussian noise\n## tmax = max number of time steps\nxo <- 1\nalpha <- 0.5\nsigma <- 1\ntmax <- 100\n\nx1 <- ac1fun(xo=xo,alpha=alpha,sigma=sigma,tmax=tmax)\n\nplot(0:tmax+1, x1, type=\"l\", lwd=2, axes=FALSE, xaxs=\"i\",\n     xlab=\"Time\", ylab=\"Income\")\nabline(h=mean(x1), col=\"red\")\naxis(1,labels=FALSE)\naxis(2,labels=FALSE)\nbox()\n\n\n\n## Calculate frequency spectrum\n\nspect <- spectrum(x1, log=\"no\", spans=c(2,2), plot=FALSE)\nspecx <- spect$freq\nspecy <- 2*spect$spec\nttext <- \"Spectrum for Positive Autocorrelation,\"\nplot(specx, specy, type=\"l\", lwd=2,\n     xlab=\"Frequency (1/day)\", ylab=\"Spectral Density\")\ntitle(bquote(.(ttext) ~ alpha==0.5))\n\n\n\n\nspectrum calculates the frequency axis in terms of cycles per sampling interval; it makes more sense to convert to cycles per unit time (so divide by the sampling interval). The spectrum is generally far more interpretable if it is smoothed. To do this, we use the argument spans, which specifies the parameter(s) for the what is known as the modified Daniell kernel for smoothing the spectrum. The modified Daniell kernel is essentially just a running average (see code below for a sense of what these parameters do). There is no hard-and-fast rule for how to do this (try a couple different values), but the higher the number of spans, the more smoothing and the lower the peaks of the spectrum will be.\nThe default for spectrum is to calculate the spectrum on a log-scale. Use the argument log=\"no\" to change this default. Note also that the spectrum needs to be multiplied by 2 to make it actually equal to variance!"
  },
  {
    "objectID": "drawing.html#how-wavelets-work",
    "href": "drawing.html#how-wavelets-work",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.17 How Wavelets Work",
    "text": "2.17 How Wavelets Work\nWavelets are like spectral analysis, but they work at multiple scales. Suppose we have a series \\(x(t)\\). The wavelet transform involves multiplying the series by the wavelet which has been stretched to various scales spanning the series and summing this product. The scale is determined by the parameter \\(\\tau\\). Note how conceptually similar this is to calculating the covariance of two variables.\n\\[\nW_x(a,\\tau) = \\frac{1}{\\sqrt{a}} \\int_{-\\infty}^{\\infty} x(t)\\psi^* \\left(\\frac{t-\\tau}{a}\\right) dt = \\int_{-\\infty}^{\\infty} x(t)\\psi^*_{a,\\tau}(t) dt\n\\]\n\nlibrary(biwavelet)\nmorlet <- function(x) exp(-x^2/2) * cos(5*x)\nx <- seq(-4,4,length=1000)\ny <- morlet(x)\nplot(x,y,type=\"l\",  lwd=3, col=\"purple4\",\n     ylim=c(-1.1,1.1),\n     xlab=\"\",ylab=expression(psi[a,tau](t)))\nabline(h=0, lwd=0.5, lty=3)\n\n\n\n\nNow generate a periodic series and overlay on the mother wavelet.\n\nf <- expression(cos(2*pi*x)*exp(-pi*x^2))\nplot(x,y,type=\"l\",  lwd=3, col=\"purple4\",\n     ylim=c(-1.1,1.1),\n     xlab=\"\",ylab=expression(psi[a,tau](t)))\nabline(h=0, lwd=0.5, lty=3)\nlines(x,eval(f), lwd=2)\n\n\n\n\nWe can see that the wavelet captures this periodic variation pretty well. The wavelet transform of the signal (red) shows that most of the function lies above the \\(x=0\\) line and its sum is strongly positive.\n\ndx <- diff(x)\ndx <- c(dx,dx[999])\n\nplot(x, y*eval(f)*dx, type=\"l\", lwd=3, col=\"red\", xlab=\"x\",\n     ylab=expression(paste(\"integrand, \", psi[a,tau](t), x(t))))\nabline(h=0, lty=2)\n\n\n\n\nWhat happens when the signal is not well matched by the wavelet? In the next figure, the signal in black is largely random with respect to the mother wavelet. When we plot the wavelet transform of this signal (red), there is approximately an equal amount of area above and below the the \\(x=0\\) line and the sum is effectively zero.\n\n# another function\nf1 <- expression(cos(12*pi*x)*exp(-pi*x^2))\nplot(x,y,type=\"l\",  lwd=3, col=\"purple4\",\n     ylim=c(-1.1,1.1),\n     xlab=\"\",ylab=expression(psi[a,tau](t)))\nabline(h=0, lwd=0.5, lty=3)\nlines(x,eval(f1), lwd=2)\n\n\n\nplot(x, y*eval(f1)*dx, type=\"l\", lwd=3, col=\"red\", xlab=\"x\",\n     ylab=expression(paste(\"integrand, \", psi[a,tau](t), x(t))))\nabline(h=0, lty=2)"
  },
  {
    "objectID": "interpreting.html#contour-plots",
    "href": "interpreting.html#contour-plots",
    "title": "1  Interpreting Scientific Figures",
    "section": "1.7 Contour Plots",
    "text": "1.7 Contour Plots"
  },
  {
    "objectID": "drawing.html#bistable-attractors",
    "href": "drawing.html#bistable-attractors",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.8 Bistable Attractors",
    "text": "2.8 Bistable Attractors\nBistability means that a dynamic system has two distinct stable states.\nEfferson, Vogt, and Fehr (2020) develop a model of cultural change with heterogeneous preferences. They show that the system is characterized by bistability.\n\n## mixture of 2 logistic curves\nf <- function(a1,b1,c1,a2,b2,c2,x,p){\n  return(x-(p*(c1/(1+exp(-(b1*(x-a1)))))+(1-p)*(0.25+c2/(1+exp(-(b2*(x-a2)))))))\n}\n\na1 <- 1/2\nb1 <- 15\nc1 <- 1\na2 <- 1/2\nb2 <- 7\nc2 <- 1/2\np <- seq(0,1,length=1000)\nlibrary(rootSolve)\nuniroot.all(f,a1=a1,b1=b1,c1=c1,a2=a2,b2=b2,c2=c2,p=0.25,interval=c(0,1))\n\n[1] 0.5000000 0.2479318 0.7520682\n\nAA <- matrix(NA,1000,3)\nfor(i in 1:1000){\n  tmp <- uniroot.all(f,a1=a1,b1=b1,c1=c1,a2=a2,b2=b2,c2=c2,p=p[i],interval=c(0,1))\n  ifelse(length(tmp)==1,AA[i,1] <- tmp, \n         ifelse(length(tmp)==2,AA[i,1:2] <- tmp, AA[i,] <- tmp))\n}\n\n## Attractor\nplot(p[-1000],AA[1:999,3],type=\"l\", lwd=3,\n     xlab=\"Proportion Wearing Masks\", \n     ylab=\"Probability of Mask Adoption\",\n     xlim=c(0,1),ylim=c(0,1))\nlines(p[-1000],AA[1:999,2], lwd=3)\nlines(p[-1000],AA[1:999,1], lty=2, lwd=3, col=\"grey\")\nlines(p[1:44],AA[1:44,1], lwd=3)\narrows(x0=c(0.2,0.4,0.6,0.8,1.0), y0=0.55, x1=c(0.2,0.4,0.6,0.8,1.0), y1=0.65, \n       lwd=3, col=\"red\", length=0.1)\narrows(x0=c(0.2,0.4,0.6,0.8,1.0), y0=0.45, x1=c(0.2,0.4,0.6,0.8,1.0), y1=0.35, \n       lwd=3, col=\"red\", length=0.1)\narrows(x0=0, y0=0.55, x1=0, y1=0.65, \n       lwd=3, col=\"red\", code=1, length=0.1)\narrows(x0=0, y0=0.45, x1=0, y1=0.35, \n       lwd=3, col=\"red\", code=1,length=0.1)"
  },
  {
    "objectID": "drawing.html#linear-programming",
    "href": "drawing.html#linear-programming",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.13 Linear Programming",
    "text": "2.13 Linear Programming\nFrom Belovsky (1987). Optimal diet for hunter-gatherers based on constraints on feeding time, digestive capacity, energy requirements, and protein needs. Uses linear programming to find the optimal solution. Belovsky shows that, contrary to much thinking about foraging, that hunter-gatherers tend to maximize either total food intake or protein and do not time-minimize.\n\n#### constraint functions\n\n## feeding time constraint\n## 393 >= 0.34*H + 0.42*G\n\ntime.slope <- -0.42/0.34\ntime.int <- 393/0.34\n\n## digestive constraint\n## 700 >= H + 0.67*G\n\ndig.slope <- -0.67\ndig.int <- 700\n\n## engergy constraint\n## 1975 =< 3*H + 3.05*G (or 3.22*G)\n\nenergy.slope <- -3.05/3\nenergy.int <- 1975/3\n\n## protein constraint\n## 60 =< 0.15*H + 0.12*G\n\nprotein.slope <- -0.12/0.15\nprotein.int <- 60/0.15\n\n\n#  polygon top is digestion until it meets time; bottom is energy\nxx <- 0:1000\nddy <- 700 - 0.67*xx\ntty <- 393/.34 - (0.42/0.34)*xx\neey <- 1975/3 - (3.05/3)*xx\n\nmin(which(tty<0))\n\n[1] 937\n\n# 937\ngg <- c(1:937, 937:1)\n\nmin(which(ddy>=tty))\n\n[1] 808\n\n# 808\nhh <- c(ddy[1:808],tty[809:937],eey[937:1])\n\n\nplot(1:1200,1:1200, type=\"n\", yaxs=\"i\", xaxs=\"i\",\n     xlab=\"Gathered Food (g)\", ylab=\"Hunted Food (g)\")\nabline(a=time.int, b=time.slope)\nabline(a=dig.int, b=dig.slope)\nabline(a=energy.int, b=energy.slope)\nabline(a=protein.int, b=protein.slope)\npolygon(gg,hh,col=grey(0.85), border=\"black\")\npoints(807,ddy[808], pch=21, cex=1.5)\nabline(h=0,lwd=2)"
  },
  {
    "objectID": "drawing.html#to-do",
    "href": "drawing.html#to-do",
    "title": "2  Theoretical Scientific Figures in R",
    "section": "2.18 To Do",
    "text": "2.18 To Do\n\nSplines\nFitness surface/contour plot\nKinship/genealogy\nPhylogenetic trees\nDAGs/causal diagrams\nLexis diagram\nShow how cobwebbed Ricker recruitment translates into chaotic time series\n\n\n\n\n\nBaalen, M. van, and M. W. Sabelis. 1995. “The Dynamics of Multiple Infection and the Evolution of Virulence.” American Naturalist 146 (6): 881–910. http://www.jstor.org/stable/2463102.\n\n\nBelovsky, G. E. 1987. “Hunter-Gatherer Foraging: A Linear Programming Approach.” Journal of Anthropological Archaeology 6 (1): 29–76. https://doi.org/10.1016/0278-4165(87)90016-X.\n\n\nCharnov, Eric L. 1976. “Optimal Foraging, the Marginal Value Theorem.” Theoretical Population Biology 9 (2): 129–36. https://doi.org/10.1016/0040-5809(76)90040-X.\n\n\n———. 1997. “Trade-Off-Invariant Rules for Evolutionary Stable Life Histories.” Nature 387 (6631): 393–94. https://doi.org/10.1038/387393a0.\n\n\nEfferson, Charles, Sonja Vogt, and Ernst Fehr. 2020. “The Promise and the Peril of Using Social Influence to Reverse Harmful Traditions.” Nature Human Behaviour 4 (1): 55–68. https://doi.org/10.1038/s41562-019-0768-2.\n\n\nHenrich, Joseph. 2004. “Demography and Cultural Evolution: How Adaptive Cultural Processes Can Produce Maladaptive Losses: The Tasmanian Case.” American Antiquity 69 (2): 197–214. https://doi.org/10.2307/4128416.\n\n\nLeslie, P., and B. Winterhalder. 2002. “Demographic Consequences of Unpredictability in Fertility Outcomes.” American Journal of Human Biology 14 (2): 168–83. https://doi.org/10.1002/ajhb.10044.\n\n\nLevins, R. 1968. Evolution in Changing Environments. Princeton: Princeton University Press.\n\n\nLevins, Richard. 1962. “Theory of Fitness in a Heterogeneous Environment. I. The Fitness Set and Adaptive Function.” The American Naturalist 96 (891): 361–73. http://www.jstor.org/stable/2458725.\n\n\nMay, R. M. 1976. “Simple Mathematical-Models with Very Complicated Dynamics.” Nature 261 (5560): 459–67. https://doi.org/10.1038/261459a0.\n\n\nOrians, Gordon H. 1969. “On the Evolution of Mating Systems in Birds and Mammals.” The American Naturalist 103 (934): 589–603. https://doi.org/10.1086/282628.\n\n\nParker, G. A., and R. A. Stuart. 1976. “Animal Behavior as a Strategy Optimizer: Evolution of Resource Assessment Strategies and Optimal Emigration Thresholds.” American Naturalist 110 (976): 1055–76. https://doi.org/10.1086/283126.\n\n\nRogers, A. R. 1988. “Does Biology Constrain Culture?” American Anthropologist 90 (4): 819–31. https://doi.org/10.1525/aa.1988.90.4.02a00030.\n\n\nRogers, E. M. 2003. Diffusion of Innovations. 5th ed. New York: Free Press.\n\n\nScheffer, M. 2009. Critical Transitions in Nature and Society. Princeton: Princeton University Press.\n\n\nSmith, C. C., and S. D. Fretwell. 1974. “The Optimal Balance Between Size and Number of Offspring.” American Naturalist 108: 499–506. https://www.jstor.org/stable/2459681.\n\n\nZeeman, E. C. 1976. “Catastrophe Theory.” Scientific American 234 (4): 65–65 &. https://doi.org/10.1038/scientificamerican0476-65."
  }
]